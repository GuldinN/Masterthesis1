{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyP6OR/94OHsA2YwZd3iYtTL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuldinN/Masterthesis1/blob/main/Kopie_von_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installs and Imports"
      ],
      "metadata": {
        "id": "spoU-STN5Isg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "A_mqzuHX966u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets transformers evaluate\n",
        "!pip install -q albumentations"
      ],
      "metadata": {
        "id": "gAu38ery9pxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Datasets"
      ],
      "metadata": {
        "id": "V4k4e6ry5N_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Download with progress bar"
      ],
      "metadata": {
        "id": "4CcbPx2m5P0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Function to download a file with a progress bar\n",
        "def download_with_progress(url, output_path):\n",
        "    response = requests.get(url, stream=True)\n",
        "    total_size = int(response.headers.get('content-length', 0))\n",
        "    chunk_size = 1024  # Size of the chunks in bytes (1 KB)\n",
        "\n",
        "    with open(output_path, 'wb') as file, tqdm(\n",
        "        desc=f'Downloading {os.path.basename(output_path)}',\n",
        "        total=total_size,\n",
        "        unit='B',\n",
        "        unit_scale=True,\n",
        "        unit_divisor=1024,\n",
        "    ) as bar:\n",
        "        for data in response.iter_content(chunk_size=chunk_size):\n",
        "            file.write(data)\n",
        "            bar.update(len(data))"
      ],
      "metadata": {
        "id": "n1xnBo4d5JlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ISIC2019"
      ],
      "metadata": {
        "id": "mf1r8C4b5aoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# URLs for the 2019 dataset\n",
        "images_url = 'https://isic-challenge-data.s3.amazonaws.com/2019/ISIC_2019_Training_Input.zip'\n",
        "metadata_url = 'https://isic-challenge-data.s3.amazonaws.com/2019/ISIC_2019_Training_GroundTruth.csv'\n",
        "\n",
        "# Define the folder structure\n",
        "output_folder = 'Datasources/ISIC2019'\n",
        "images_folder = os.path.join(output_folder, 'images')\n",
        "metadata_csv_path = os.path.join(output_folder, 'ISIC_2019_Training_GroundTruth.csv')\n",
        "\n",
        "# Check if images need to be downloaded\n",
        "if not os.path.exists(images_folder):\n",
        "    os.makedirs(images_folder)\n",
        "\n",
        "    # Download images\n",
        "    images_zip_path = os.path.join(output_folder, 'images.zip')\n",
        "    download_with_progress(images_url, images_zip_path)\n",
        "    print(\"Images successfully downloaded.\")\n",
        "\n",
        "    # Extract images\n",
        "    with zipfile.ZipFile(images_zip_path, 'r') as z:\n",
        "        z.extractall(images_folder)\n",
        "        print(\"Images successfully extracted to:\", images_folder)\n",
        "    os.remove(images_zip_path)  # Delete ZIP file after extraction\n",
        "else:\n",
        "    print(f\"The folder '{images_folder}' already exists. Image download skipped.\")\n",
        "\n",
        "# Check if metadata needs to be downloaded\n",
        "if not os.path.exists(metadata_csv_path):\n",
        "    # Download metadata\n",
        "    download_with_progress(metadata_url, metadata_csv_path)\n",
        "    print(\"Metadata successfully downloaded and saved under:\", metadata_csv_path)\n",
        "else:\n",
        "    print(\"The metadata file already exists. Metadata download skipped.\")"
      ],
      "metadata": {
        "id": "Yh5aS-095cwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PAD-UFES-20"
      ],
      "metadata": {
        "id": "v9g82rfl5iT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "output_folder = 'Datasources/PADUFES20'\n",
        "data_url = 'https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/zr7vgbcyr2-1.zip'\n",
        "\n",
        "if not os.path.exists(output_folder):\n",
        "  os.makedirs(output_folder)\n",
        "\n",
        "  # Download data\n",
        "  images_zip_path = os.path.join(output_folder, 'images.zip')\n",
        "  download_with_progress(data_url, images_zip_path)\n",
        "  print(\"Images successfully downloaded.\")\n",
        "\n",
        "  # Extract data\n",
        "  with zipfile.ZipFile(images_zip_path, 'r') as z:\n",
        "      z.extractall(output_folder)\n",
        "      print(\"Data successfully extracted to:\", output_folder)\n",
        "  os.remove(images_zip_path)  # Delete ZIP file after extraction\n",
        "\n",
        "  zf = zipfile.ZipFile('/content/Datasources/PADUFES20/images/imgs_part_1.zip', 'r')\n",
        "  zf.extractall('/content/Datasources/PADUFES20/images')\n",
        "  print(\"Images 1 successfully extracted to:\", '/content/Datasources/PADUFES20/images')\n",
        "  os.remove('/content/Datasources/PADUFES20/images/imgs_part_1.zip')  # Delete ZIP file after extraction\n",
        "\n",
        "  zf = zipfile.ZipFile('/content/Datasources/PADUFES20/images/imgs_part_2.zip', 'r')\n",
        "  zf.extractall('/content/Datasources/PADUFES20/images')\n",
        "  print(\"Images 2 successfully extracted to:\", '/content/Datasources/PADUFES20/images')\n",
        "  os.remove('/content/Datasources/PADUFES20/images/imgs_part_2.zip')  # Delete ZIP file after extraction\n",
        "\n",
        "  zf = zipfile.ZipFile('/content/Datasources/PADUFES20/images/imgs_part_3.zip', 'r')\n",
        "  zf.extractall('/content/Datasources/PADUFES20/images')\n",
        "  print(\"Images 3 successfully extracted to:\", '/content/Datasources/PADUFES20/images')\n",
        "  os.remove('/content/Datasources/PADUFES20/images/imgs_part_3.zip')  # Delete ZIP file after extraction\n",
        "\n",
        "  #Move files\n",
        "  source = \"/content/Datasources/PADUFES20/images/imgs_part_1\"\n",
        "  destination = \"/content/Datasources/PADUFES20/images\"\n",
        "  files = os.listdir(source)\n",
        "  for file in files:\n",
        "    file_name = os.path.join(source, file)\n",
        "    shutil.move(file_name, destination)\n",
        "  print(\"Files 1 Moved\")\n",
        "  os.rmdir(\"/content/Datasources/PADUFES20/images/imgs_part_1\")\n",
        "\n",
        "  source = \"/content/Datasources/PADUFES20/images/imgs_part_2\"\n",
        "  destination = \"/content/Datasources/PADUFES20/images\"\n",
        "  files = os.listdir(source)\n",
        "  for file in files:\n",
        "    file_name = os.path.join(source, file)\n",
        "    shutil.move(file_name, destination)\n",
        "  print(\"Files 2 Moved\")\n",
        "  os.rmdir(\"/content/Datasources/PADUFES20/images/imgs_part_2\")\n",
        "\n",
        "  source = \"/content/Datasources/PADUFES20/images/imgs_part_3\"\n",
        "  destination = \"/content/Datasources/PADUFES20/images\"\n",
        "  files = os.listdir(source)\n",
        "  for file in files:\n",
        "    file_name = os.path.join(source, file)\n",
        "    shutil.move(file_name, destination)\n",
        "  print(\"Files 3 Moved\")\n",
        "  os.rmdir(\"/content/Datasources/PADUFES20/images/imgs_part_3\")"
      ],
      "metadata": {
        "id": "4hNcY1Gv5lQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze Datasources"
      ],
      "metadata": {
        "id": "sEkEX2Oy5tLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV and map labels\n",
        "csv_path = '/content/Datasources/ISIC2019/ISIC_2019_Training_GroundTruth.csv'\n",
        "images_folder = '/content/Datasources/ISIC2019/images/ISIC_2019_Training_Input'\n",
        "ISIC2019_df = pd.read_csv(csv_path)\n",
        "\n",
        "label_mapping = {\n",
        "    'MEL': 'MEL',\n",
        "    'NV': 'NEV',\n",
        "    'BCC': 'BCC',\n",
        "    'AK': 'ACK',\n",
        "    'BKL': 'BKL',\n",
        "    'DF': 'DF',\n",
        "    'VASC': 'VASC',\n",
        "    'SCC': 'SCC',\n",
        "    'UNK': 'UNK'\n",
        "}\n",
        "\n",
        "# Map labels to single label column\n",
        "ISIC2019_df['label'] = ISIC2019_df[['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']].idxmax(axis=1).map(label_mapping)\n",
        "\n",
        "# Create image paths\n",
        "ISIC2019_df['image_path'] = ISIC2019_df['image'].apply(lambda x: os.path.join(images_folder, f\"{x}.jpg\"))\n",
        "#ISIC2019_df['image_id'] = ISIC2019_df['image']\n",
        "\n",
        "# Filter necessary columns\n",
        "ISIC2019_df = ISIC2019_df[['image_path', 'label']]\n",
        "\n",
        "# Display class distribution (absolute and relative)\n",
        "class_distribution = ISIC2019_df['label'].value_counts()\n",
        "class_distribution_relative = ISIC2019_df['label'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(f\"{len(ISIC2019_df)} images\")\n",
        "print(\"\\nClass Distribution (absolute):\")\n",
        "print(class_distribution)\n",
        "print(\"\\nClass Distribution (relative %):\")\n",
        "print(class_distribution_relative)\n",
        "\n",
        "ISIC2019_df"
      ],
      "metadata": {
        "id": "hC7ffgcH5n3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV and map labels\n",
        "csv_path = '/content/Datasources/PADUFES20/metadata.csv'\n",
        "images_folder = '/content/Datasources/PADUFES20/images'\n",
        "PADUFES20_df = pd.read_csv(csv_path)\n",
        "\n",
        "# Map labels to single label column\n",
        "PADUFES20_df['label'] = PADUFES20_df['diagnostic']\n",
        "\n",
        "# Create image paths\n",
        "#PADUFES20_df['image_id'] = PADUFES20_df['img_id']\n",
        "PADUFES20_df['image_path'] = PADUFES20_df['img_id'].apply(lambda x: os.path.join(images_folder, f\"{x}\"))\n",
        "\n",
        "\n",
        "# Filter necessary columns\n",
        "PADUFES20_df = PADUFES20_df[['image_path', 'label']]\n",
        "\n",
        "# Display class distribution (absolute and relative)\n",
        "class_distribution = PADUFES20_df['label'].value_counts()\n",
        "class_distribution_relative = PADUFES20_df['label'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(f\"{len(PADUFES20_df)} images\")\n",
        "print(\"\\nClass Distribution (absolute):\")\n",
        "print(class_distribution)\n",
        "print(\"\\nClass Distribution (relative %):\")\n",
        "print(class_distribution_relative)\n",
        "\n",
        "PADUFES20_df"
      ],
      "metadata": {
        "id": "oUIjANbA5r-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Custom Dataframes"
      ],
      "metadata": {
        "id": "GyrdejBW6ljs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#Dermoscopic\n",
        "#BCC Dermoscopic\n",
        "remove_n = 2478\n",
        "bcc_df_dermoscopic = ISIC2019_df[ISIC2019_df['label'] == 'BCC']\n",
        "drop_indices = np.random.choice(bcc_df_dermoscopic.index, remove_n, replace=False)\n",
        "bcc_df = bcc_df_dermoscopic.drop(drop_indices)\n",
        "\n",
        "df_train_dermoscopic_bcc = bcc_df.sample(frac=0.8,random_state=200)\n",
        "df_test_dermoscopic_bcc = bcc_df.drop(df_train_dermoscopic_bcc.index)\n",
        "\n",
        "#SCC Dermoscopic\n",
        "remove_n = 436\n",
        "scc_df_dermoscopic = ISIC2019_df[ISIC2019_df['label'] == 'SCC']\n",
        "drop_indices = np.random.choice(scc_df_dermoscopic.index, remove_n, replace=False)\n",
        "scc_df = scc_df_dermoscopic.drop(drop_indices)\n",
        "\n",
        "df_train_dermoscopic_scc = scc_df.sample(frac=0.8,random_state=200)\n",
        "df_test_dermoscopic_scc = scc_df.drop(df_train_dermoscopic_scc.index)\n",
        "\n",
        "df_train_dermoscopic = pd.concat([df_train_dermoscopic_bcc, df_train_dermoscopic_scc], ignore_index=True)\n",
        "df_train_dermoscopic = df_train_dermoscopic.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df_test_dermoscopic = pd.concat([df_test_dermoscopic_bcc, df_test_dermoscopic_scc], ignore_index=True)\n",
        "df_test_dermoscopic = df_test_dermoscopic.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#Clinical\n",
        "#BCC Clinical\n",
        "bcc_df_clinical = PADUFES20_df[PADUFES20_df['label'] == 'BCC']\n",
        "\n",
        "df_train_clinical_bcc = bcc_df_clinical.sample(frac=0.8,random_state=200)\n",
        "df_test_clinical_bcc = bcc_df_clinical.drop(df_train_clinical_bcc.index)\n",
        "\n",
        "#SCC Clinical\n",
        "scc_df_clinical = PADUFES20_df[PADUFES20_df['label'] == 'SCC']\n",
        "\n",
        "df_train_clinical_scc = scc_df_clinical.sample(frac=0.8,random_state=200)\n",
        "df_test_clinical_scc = scc_df_clinical.drop(df_train_clinical_scc.index)\n",
        "\n",
        "df_train_clinical = pd.concat([df_train_clinical_bcc, df_train_clinical_scc], ignore_index=True)\n",
        "df_train_clinical = df_train_clinical.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df_test_clinical = pd.concat([df_test_clinical_bcc, df_test_clinical_scc], ignore_index=True)\n",
        "df_test_clinical = df_test_clinical.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#Mixed - Train\n",
        "#BCC Mixed\n",
        "remove_n = 338\n",
        "bcc_df_mixed_1 = df_train_dermoscopic_bcc\n",
        "drop_indices = np.random.choice(df_train_dermoscopic_bcc.index, remove_n, replace=False)\n",
        "bcc_df_mixed_1 = bcc_df_mixed_1.drop(drop_indices)\n",
        "\n",
        "bcc_df_mixed_2 = df_train_clinical_bcc\n",
        "drop_indices = np.random.choice(df_train_clinical_bcc.index, remove_n, replace=False)\n",
        "bcc_df_mixed_2 = bcc_df_mixed_2.drop(drop_indices)\n",
        "\n",
        "df_train_mixed_bcc = pd.concat([bcc_df_mixed_1, bcc_df_mixed_2], ignore_index=True)\n",
        "df_train_mixed_bcc = df_train_mixed_bcc.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#SCC Mixed\n",
        "remove_n = 77\n",
        "scc_df_mixed_1 = df_train_dermoscopic_scc\n",
        "drop_indices = np.random.choice(df_train_dermoscopic_scc.index, remove_n, replace=False)\n",
        "scc_df_mixed_1 = scc_df_mixed_1.drop(drop_indices)\n",
        "\n",
        "scc_df_mixed_2 = df_train_clinical_scc\n",
        "drop_indices = np.random.choice(df_train_clinical_scc.index, remove_n, replace=False)\n",
        "scc_df_mixed_2 = scc_df_mixed_2.drop(drop_indices)\n",
        "\n",
        "df_train_mixed_scc = pd.concat([scc_df_mixed_1, scc_df_mixed_2], ignore_index=True)\n",
        "df_train_mixed_scc = df_train_mixed_scc.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df_train_mixed = pd.concat([df_train_mixed_bcc, df_train_mixed_scc], ignore_index=True)\n",
        "df_train_mixed = df_train_mixed.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#Mixed - Test\n",
        "#BCC Mixed\n",
        "remove_n = 84\n",
        "bcc_df_mixed_1_test = df_test_dermoscopic_bcc\n",
        "drop_indices = np.random.choice(df_test_dermoscopic_bcc.index, remove_n, replace=False)\n",
        "bcc_df_mixed_1_test = bcc_df_mixed_1_test.drop(drop_indices)\n",
        "\n",
        "remove_n = 85\n",
        "bcc_df_mixed_2_test = df_test_clinical_bcc\n",
        "drop_indices = np.random.choice(df_test_clinical_bcc.index, remove_n, replace=False)\n",
        "bcc_df_mixed_2_test = bcc_df_mixed_2_test.drop(drop_indices)\n",
        "\n",
        "df_test_mixed_bcc = pd.concat([bcc_df_mixed_1_test, bcc_df_mixed_2_test], ignore_index=True)\n",
        "df_test_mixed_bcc = df_test_mixed_bcc.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#SCC Mixed\n",
        "remove_n = 19\n",
        "scc_df_mixed_1_test = df_test_dermoscopic_scc\n",
        "drop_indices = np.random.choice(df_test_dermoscopic_scc.index, remove_n, replace=False)\n",
        "scc_df_mixed_1_test = scc_df_mixed_1_test.drop(drop_indices)\n",
        "\n",
        "scc_df_mixed_2_test = df_test_clinical_scc\n",
        "drop_indices = np.random.choice(df_test_clinical_scc.index, remove_n, replace=False)\n",
        "scc_df_mixed_2_test = scc_df_mixed_2_test.drop(drop_indices)\n",
        "\n",
        "df_test_mixed_scc = pd.concat([scc_df_mixed_1_test, scc_df_mixed_2_test], ignore_index=True)\n",
        "df_test_mixed_scc = df_test_mixed_scc.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df_test_mixed = pd.concat([df_test_mixed_bcc, df_test_mixed_scc], ignore_index=True)\n",
        "df_test_mixed = df_test_mixed.sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "nI7_X6WpbI4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataframe Dermoscopic Train Set\n",
        "print(\"Dermoscopic Train Set \")\n",
        "print(f\"Dataset Größe: {len(df_train_dermoscopic)}\")\n",
        "print(df_train_dermoscopic['label'].value_counts())\n",
        "#Dataframe Dermoscopic Test Set\n",
        "print(\"Dermoscopic Test Set \")\n",
        "print(f\"Dataset Größe: {len(df_test_dermoscopic)}\")\n",
        "print(df_test_dermoscopic['label'].value_counts())\n",
        "#Dataframe Clinical Train Set\n",
        "print(\"Clinical Train Set \")\n",
        "print(f\"Dataset Größe: {len(df_train_clinical)}\")\n",
        "print(df_train_clinical['label'].value_counts())\n",
        "#Dataframe Clinical Test Set\n",
        "print(\"Clinical Test Set \")\n",
        "print(f\"Dataset Größe: {len(df_test_clinical)}\")\n",
        "print(df_test_clinical['label'].value_counts())\n",
        "#Dataframe Mixed Train Set\n",
        "print(\"Mixed Train Set \")\n",
        "print(f\"Dataset Größe: {len(df_train_mixed)}\")\n",
        "print(df_train_mixed['label'].value_counts())\n",
        "#Dataframe Mixed Test Set\n",
        "print(\"Mixed Test Set \")\n",
        "print(f\"Dataset Größe: {len(df_test_mixed)}\")\n",
        "print(df_test_mixed['label'].value_counts())"
      ],
      "metadata": {
        "id": "ROF7NiHr6se-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from PIL import Image\n",
        "from datasets import Features, ClassLabel, Image as ImageFeature\n",
        "\n",
        "#Training Sets - Will be later split into train and val set\n",
        "df_dermoscopic = df_train_dermoscopic.copy()\n",
        "df_dermoscopic = df_dermoscopic.rename(columns={'image_path': 'image'})\n",
        "df_dermoscopic['label'] = df_dermoscopic['label'].apply(lambda x: 1 if x == 'BCC' else 0)\n",
        "\n",
        "df_clinical = df_train_clinical.copy()\n",
        "df_clinical = df_clinical.rename(columns={'image_path': 'image'})\n",
        "df_clinical['label'] = df_clinical['label'].apply(lambda x: 1 if x == 'BCC' else 0)\n",
        "\n",
        "df_mixed = df_train_mixed.copy()\n",
        "df_mixed = df_mixed.rename(columns={'image_path': 'image'})\n",
        "df_mixed['label'] = df_mixed['label'].apply(lambda x: 1 if x == 'BCC' else 0)\n",
        "\n",
        "#Test Sets\n",
        "df_dermoscopic_test = df_test_dermoscopic.copy()\n",
        "df_dermoscopic_test = df_dermoscopic_test.rename(columns={'image_path': 'image'})\n",
        "df_dermoscopic_test['label'] = df_dermoscopic_test['label'].apply(lambda x: 1 if x == 'BCC' else 0)\n",
        "\n",
        "df_clinical_test = df_test_clinical.copy()\n",
        "df_clinical_test = df_clinical_test.rename(columns={'image_path': 'image'})\n",
        "df_clinical_test['label'] = df_clinical_test['label'].apply(lambda x: 1 if x == 'BCC' else 0)\n",
        "\n",
        "df_mixed_test = df_test_mixed.copy()\n",
        "df_mixed_test = df_mixed_test.rename(columns={'image_path': 'image'})\n",
        "df_mixed_test['label'] = df_mixed_test['label'].apply(lambda x: 1 if x == 'BCC' else 0)\n",
        "\n",
        "ds_dermoscopic_train = Dataset.from_pandas(df_dermoscopic)\n",
        "ds_clinical_train = Dataset.from_pandas(df_clinical)\n",
        "ds_mixed_train = Dataset.from_pandas(df_mixed)\n",
        "\n",
        "ds_dermoscopic_test = Dataset.from_pandas(df_dermoscopic_test)\n",
        "ds_clinical_test = Dataset.from_pandas(df_clinical_test)\n",
        "ds_mixed_test = Dataset.from_pandas(df_mixed_test)\n",
        "\n",
        "# Cast columns as features\n",
        "ds_dermoscopic_train = ds_dermoscopic_train.cast_column(\"label\", ClassLabel(num_classes=2, names=['SCC', 'BCC']))\n",
        "ds_dermoscopic_train = ds_dermoscopic_train.cast_column(\"image\", ImageFeature())\n",
        "\n",
        "ds_clinical_train = ds_clinical_train.cast_column(\"label\", ClassLabel(num_classes=2, names=['SCC', 'BCC']))\n",
        "ds_clinical_train = ds_clinical_train.cast_column(\"image\", ImageFeature())\n",
        "\n",
        "ds_mixed_train = ds_mixed_train.cast_column(\"label\", ClassLabel(num_classes=2, names=['SCC', 'BCC']))\n",
        "ds_mixed_train = ds_mixed_train.cast_column(\"image\", ImageFeature())\n",
        "\n",
        "ds_dermoscopic_test = ds_dermoscopic_test.cast_column(\"label\", ClassLabel(num_classes=2, names=['SCC', 'BCC']))\n",
        "ds_dermoscopic_test = ds_dermoscopic_test.cast_column(\"image\", ImageFeature())\n",
        "\n",
        "ds_clinical_test = ds_clinical_test.cast_column(\"label\", ClassLabel(num_classes=2, names=['SCC', 'BCC']))\n",
        "ds_clinical_test = ds_clinical_test.cast_column(\"image\", ImageFeature())\n",
        "\n",
        "ds_mixed_test = ds_mixed_test.cast_column(\"label\", ClassLabel(num_classes=2, names=['SCC', 'BCC']))\n",
        "ds_mixed_test = ds_mixed_test.cast_column(\"image\", ImageFeature())"
      ],
      "metadata": {
        "id": "a_9nYRJe-3R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reused Functions"
      ],
      "metadata": {
        "id": "EqqvFlnPM1pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ds_dermoscopic_train.features['label'].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label\n",
        "\n",
        "num_labels = len(id2label)\n",
        "\n",
        "labeldict = ds_dermoscopic_train['label']"
      ],
      "metadata": {
        "id": "5302NOE3Gu3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot Trainning, Validation Loss and Accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_metrics(history):\n",
        "    # Plot Training and Validation Loss\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history['loss'], label='Training Loss')\n",
        "    plt.plot(history['eval_loss'], label='Validation Loss')\n",
        "    plt.plot([0, 1], [0, 1], alpha=0)\n",
        "    plt.xticks(plt.xticks()[0][1::2]);\n",
        "    #plt.xlim(0, 30)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Metric (e.g., Accuracy or other metric)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history['eval_accuracy'], label='Accuracy')\n",
        "    plt.plot(history['eval_precision'], label='Precision')\n",
        "    plt.plot(history['eval_recall'], label='Recall')\n",
        "    plt.plot(history['eval_f1'], label='F1 Score')\n",
        "    plt.plot([0.6, 1], [1, 1], alpha=0)\n",
        "    plt.xticks(plt.xticks()[0][1::2]);\n",
        "    #plt.xlim([0, 30])\n",
        "    #plt.ylim([0.6, 1])\n",
        "    plt.xlabel('Epochs')\n",
        "    #plt.ylabel('Accuracy')\n",
        "    plt.title('Accurcay, Precision, Recall, F1 Progress')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XAjN5Y-pM9al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot ConfusionMatrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def plot_confusion_matrix(outputs):\n",
        "  y_true = outputs.label_ids\n",
        "  y_pred = np.argmax(outputs.predictions, axis=1)\n",
        "\n",
        "  labels = train_dataset.features['label'].names\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "  disp.plot(xticks_rotation=45)"
      ],
      "metadata": {
        "id": "n4k8bSKDNLbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot Roc curve\n",
        "\n",
        "from scipy.special import softmax\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "def plot_roc_curve(outputs):\n",
        "    probabilities = softmax(outputs.predictions, axis=1)\n",
        "    probabilities = probabilities[:, 1]\n",
        "\n",
        "    y_pred_proba = probabilities\n",
        "\n",
        "    # Calculate ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(outputs.label_ids, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    # Plot the ROC curve\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "eRBOSB8zNRIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training CNN (Dermoscopic)"
      ],
      "metadata": {
        "id": "pjJ_p5c-yhlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "\n",
        "model_checkpoint = \"timm/resnet50.tv_in1k\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "image_processor = image_processor.data_config\n",
        "image_processor"
      ],
      "metadata": {
        "id": "opLS5wlHJp8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "      # Geometric Transforms\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05, scale_limit=0.05, rotate_limit=10,\n",
        "        border_mode=cv2.BORDER_REFLECT_101, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Photometric Adjustments\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=0.2, contrast_limit=0.4, p=0.5\n",
        "    ),\n",
        "    A.HueSaturationValue(\n",
        "        hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=30, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Slight blur for optical variance\n",
        "    A.OneOf([\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "        A.MedianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Minor elastic distortion to simulate skin curvature\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=0.5, sigma=20, p=0.5),\n",
        "        A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Slight shadow/illumination simulation\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 3), shadow_dimension=3, shadow_intensity_range=(0.05, 0.1), p=0.2),\n",
        "    A.RandomSunFlare(src_radius=2, flare_roi=(0, 0, 0.2, 0.2), num_flare_circles_range=(1, 2), p=0.2),\n",
        "\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "def preprocess_train(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #train_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        train_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "def preprocess_val(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #val_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        val_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "# split up training into training + validation\n",
        "splits = ds_dermoscopic_train.train_test_split(test_size=0.1)\n",
        "train_ds_dermoscopic = splits['train']\n",
        "val_ds_dermoscopic = splits['test']\n",
        "\n",
        "splits = ds_clinical_train.train_test_split(test_size=0.1)\n",
        "train_ds_clinical = splits['train']\n",
        "val_ds_clinical = splits['test']\n",
        "\n",
        "splits = ds_mixed_train.train_test_split(test_size=0.1)\n",
        "train_ds_mixed = splits['train']\n",
        "val_ds_mixed = splits['test']\n",
        "\n",
        "test_ds_dermoscopic = ds_dermoscopic_test\n",
        "test_ds_clinical = ds_clinical_test\n",
        "test_ds_mixed = ds_mixed_test\n",
        "\n",
        "train_ds_dermoscopic.set_transform(preprocess_train)\n",
        "val_ds_dermoscopic.set_transform(preprocess_val)\n",
        "test_ds_dermoscopic.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_clinical.set_transform(preprocess_train)\n",
        "val_ds_clinical.set_transform(preprocess_val)\n",
        "test_ds_clinical.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_mixed.set_transform(preprocess_train)\n",
        "val_ds_mixed.set_transform(preprocess_val)\n",
        "test_ds_mixed.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "WsivF3NaKB5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e84950f5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "example = train_ds_clinical[29]\n",
        "original_image = example['image']\n",
        "augmented_image = example['pixel_values']\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "axes[0].imshow(original_image)\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(augmented_image)\n",
        "axes[1].set_title(\"Augmented Image\")\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "K93Q8eH6QCen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DefaultDataCollator\n",
        "import evaluate\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "metric1 = evaluate.load(\"accuracy\")\n",
        "metric2 = evaluate.load(\"precision\")\n",
        "metric3 = evaluate.load(\"recall\")\n",
        "metric4 = evaluate.load(\"f1\")\n",
        "metric5 = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "\n",
        "    accuracy = metric1.compute(predictions=predictions, references=eval_pred.label_ids)[\"accuracy\"]\n",
        "    precision = metric2.compute(predictions=predictions, references=eval_pred.label_ids)[\"precision\"]\n",
        "    recall = metric3.compute(predictions=predictions, references=eval_pred.label_ids)[\"recall\"]\n",
        "    f1 = metric4.compute(predictions=predictions, references=eval_pred.label_ids)[\"f1\"]\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "output_dir = f\"{model_name}-finetuned\"\n",
        "\n",
        "learning_rate = 1e-4 #1e-5\n",
        "batch_size = 64 #32\n",
        "num_epochs = 50\n",
        "\n",
        "def collate_fn(examples):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for example in examples:\n",
        "        image = np.moveaxis(example[\"pixel_values\"], source=2, destination=0)\n",
        "        images.append(torch.from_numpy(image))\n",
        "        labels.append(example[\"label\"])\n",
        "\n",
        "    pixel_values = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "MltTDlj-kX8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c982ec73"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classweight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labeldict), y=labeldict)\n",
        "classweight = torch.tensor(classweight, dtype=torch.float)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    logging_strategy = \"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type = \"cosine_with_restarts\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss_func(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.BCELoss(weight=classweight)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainset: Dermoscopic"
      ],
      "metadata": {
        "id": "oWqUtTZk2of8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_ds_dermoscopic\n",
        "eval_dataset = val_ds_dermoscopic\n",
        "\n",
        "trainer_cnn_dermoscopic = CustomTrainer(\n",
        "    model,\n",
        "    args = training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        "    callbacks=[EarlyStoppingCallback(10)],\n",
        ")"
      ],
      "metadata": {
        "id": "xG3Dvm-1nLlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_cnn_dermoscopic.train()"
      ],
      "metadata": {
        "id": "8YwnRmh3R52B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "df = pd.DataFrame(trainer_cnn_dermoscopic.state.log_history)\n",
        "df_history = pd.concat([df['loss'][df['loss'] > 0].reset_index(drop=True), df['eval_loss'][df['eval_loss'] > 0].reset_index(drop=True), df['eval_accuracy'][df['eval_accuracy'] > 0].reset_index(drop=True), df['eval_precision'][df['eval_precision'] > 0].reset_index(drop=True), df['eval_recall'][df['eval_recall'] > 0].reset_index(drop=True), df['eval_f1'][df['eval_f1'] > 0].reset_index(drop=True)], axis=1, ignore_index=True)\n",
        "df_history.columns = ['loss', 'eval_loss', 'eval_accuracy', 'eval_precision', 'eval_recall', 'eval_f1']\n",
        "df_history.index += 1\n",
        "\n",
        "plot_training_metrics(df_history)"
      ],
      "metadata": {
        "id": "n_dTTat3CsNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Dermoscopic"
      ],
      "metadata": {
        "id": "vrGPPo4_9Fpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_cnn_d_d = trainer_cnn_dermoscopic.predict(test_ds_dermoscopic)\n",
        "print(outputs_cnn_d_d.metrics)\n",
        "plot_confusion_matrix(outputs_cnn_d_d)\n",
        "plot_roc_curve(outputs_cnn_d_d)"
      ],
      "metadata": {
        "id": "vIPA4VWYjWHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Clinical"
      ],
      "metadata": {
        "id": "LkuaQfov9MRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_cnn_d_c = trainer_cnn_dermoscopic.predict(test_ds_clinical)\n",
        "print(outputs_cnn_d_c.metrics)\n",
        "plot_confusion_matrix(outputs_cnn_d_c)\n",
        "plot_roc_curve(outputs_cnn_d_c)"
      ],
      "metadata": {
        "id": "ghbt1JhpfT0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Mixed"
      ],
      "metadata": {
        "id": "Mym9TFMX9ON8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_cnn_d_m = trainer_cnn_dermoscopic.predict(test_ds_mixed)\n",
        "print(outputs_cnn_d_m.metrics)\n",
        "plot_confusion_matrix(outputs_cnn_d_m)\n",
        "plot_roc_curve(outputs_cnn_d_m)"
      ],
      "metadata": {
        "id": "Ykc7wppfucaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/resnet50.tv_in1k-finetuned')"
      ],
      "metadata": {
        "id": "leKMw7Cn79VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training CNN (Clinical)"
      ],
      "metadata": {
        "id": "ppcx7V5Qrb-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "\n",
        "model_checkpoint = \"timm/resnet50.tv_in1k\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "image_processor = image_processor.data_config\n",
        "image_processor"
      ],
      "metadata": {
        "id": "M-rcremdrbRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "      # Geometric Transforms\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05, scale_limit=0.05, rotate_limit=10,\n",
        "        border_mode=cv2.BORDER_REFLECT_101, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Photometric Adjustments\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=0.2, contrast_limit=0.4, p=0.5\n",
        "    ),\n",
        "    A.HueSaturationValue(\n",
        "        hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=30, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Slight blur for optical variance\n",
        "    A.OneOf([\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "        A.MedianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Minor elastic distortion to simulate skin curvature\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=0.5, sigma=20, p=0.5),\n",
        "        A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Slight shadow/illumination simulation\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 3), shadow_dimension=3, shadow_intensity_range=(0.05, 0.1), p=0.2),\n",
        "    A.RandomSunFlare(src_radius=2, flare_roi=(0, 0, 0.2, 0.2), num_flare_circles_range=(1, 2), p=0.2),\n",
        "\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "def preprocess_train(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #train_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        train_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "def preprocess_val(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #val_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        val_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "# split up training into training + validation\n",
        "splits = ds_dermoscopic_train.train_test_split(test_size=0.1)\n",
        "train_ds_dermoscopic = splits['train']\n",
        "val_ds_dermoscopic = splits['test']\n",
        "\n",
        "splits = ds_clinical_train.train_test_split(test_size=0.1)\n",
        "train_ds_clinical = splits['train']\n",
        "val_ds_clinical = splits['test']\n",
        "\n",
        "splits = ds_mixed_train.train_test_split(test_size=0.1)\n",
        "train_ds_mixed = splits['train']\n",
        "val_ds_mixed = splits['test']\n",
        "\n",
        "test_ds_dermoscopic = ds_dermoscopic_test\n",
        "test_ds_clinical = ds_clinical_test\n",
        "test_ds_mixed = ds_mixed_test\n",
        "\n",
        "train_ds_dermoscopic.set_transform(preprocess_train)\n",
        "val_ds_dermoscopic.set_transform(preprocess_val)\n",
        "test_ds_dermoscopic.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_clinical.set_transform(preprocess_train)\n",
        "val_ds_clinical.set_transform(preprocess_val)\n",
        "test_ds_clinical.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_mixed.set_transform(preprocess_train)\n",
        "val_ds_mixed.set_transform(preprocess_val)\n",
        "test_ds_mixed.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "E181OmIbrhsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "IcsKIyoIrmfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DefaultDataCollator\n",
        "import evaluate\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "metric1 = evaluate.load(\"accuracy\")\n",
        "metric2 = evaluate.load(\"precision\")\n",
        "metric3 = evaluate.load(\"recall\")\n",
        "metric4 = evaluate.load(\"f1\")\n",
        "metric5 = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "\n",
        "    accuracy = metric1.compute(predictions=predictions, references=eval_pred.label_ids)[\"accuracy\"]\n",
        "    precision = metric2.compute(predictions=predictions, references=eval_pred.label_ids)[\"precision\"]\n",
        "    recall = metric3.compute(predictions=predictions, references=eval_pred.label_ids)[\"recall\"]\n",
        "    f1 = metric4.compute(predictions=predictions, references=eval_pred.label_ids)[\"f1\"]\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "output_dir = f\"{model_name}-finetuned\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "\n",
        "def collate_fn(examples):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for example in examples:\n",
        "        image = np.moveaxis(example[\"pixel_values\"], source=2, destination=0)\n",
        "        images.append(torch.from_numpy(image))\n",
        "        labels.append(example[\"label\"])\n",
        "\n",
        "    pixel_values = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "yoph6I8Mrnzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classweight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labeldict), y=labeldict)\n",
        "classweight = torch.tensor(classweight, dtype=torch.float)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    logging_strategy = \"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type = \"cosine_with_restarts\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss_func(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.BCELoss(weight=classweight)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "gMAjZYILrvtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainset: Clinical"
      ],
      "metadata": {
        "id": "z40GL3Db2xEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_ds_clinical\n",
        "eval_dataset = val_ds_clinical\n",
        "\n",
        "trainer_cnn_clinical = CustomTrainer(\n",
        "    model,\n",
        "    args = training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        "    callbacks=[EarlyStoppingCallback(10)],\n",
        ")"
      ],
      "metadata": {
        "id": "3Wy_jzgz2KDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_cnn_clinical.train()"
      ],
      "metadata": {
        "id": "ZaciBM062U44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "df = pd.DataFrame(trainer_cnn_clinical.state.log_history)\n",
        "df_history = pd.concat([df['loss'][df['loss'] > 0].reset_index(drop=True), df['eval_loss'][df['eval_loss'] > 0].reset_index(drop=True), df['eval_accuracy'][df['eval_accuracy'] > 0].reset_index(drop=True), df['eval_precision'][df['eval_precision'] > 0].reset_index(drop=True), df['eval_recall'][df['eval_recall'] > 0].reset_index(drop=True), df['eval_f1'][df['eval_f1'] > 0].reset_index(drop=True)], axis=1, ignore_index=True)\n",
        "df_history.columns = ['loss', 'eval_loss', 'eval_accuracy', 'eval_precision', 'eval_recall', 'eval_f1']\n",
        "df_history.index += 1\n",
        "\n",
        "plot_training_metrics(df_history)"
      ],
      "metadata": {
        "id": "IdY4td9sX0QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Dermoscopic"
      ],
      "metadata": {
        "id": "90J-ezhl9Rf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_cnn_c_d = trainer_cnn_clinical.predict(test_ds_dermoscopic)\n",
        "print(outputs_cnn_c_d.metrics)\n",
        "plot_confusion_matrix(outputs_cnn_c_d)\n",
        "plot_roc_curve(outputs_cnn_c_d)"
      ],
      "metadata": {
        "id": "0Zl7_aur2PZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Clinical"
      ],
      "metadata": {
        "id": "_GEtWvXa9SUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_cnn_c_c = trainer_cnn_clinical.predict(test_ds_clinical)\n",
        "print(outputs_cnn_c_c.metrics)\n",
        "plot_confusion_matrix(outputs_cnn_c_c)\n",
        "plot_roc_curve(outputs_cnn_c_c)"
      ],
      "metadata": {
        "id": "73TcSCAL2RE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Mixed"
      ],
      "metadata": {
        "id": "KXcMfan69Utt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_cnn_c_m = trainer_cnn_clinical.predict(test_ds_mixed)\n",
        "print(outputs_cnn_c_m.metrics)\n",
        "plot_confusion_matrix(outputs_cnn_c_m)\n",
        "plot_roc_curve(outputs_cnn_c_m)"
      ],
      "metadata": {
        "id": "4OtL1_uQ2R1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/resnet50.tv_in1k-finetuned')"
      ],
      "metadata": {
        "id": "TAu2L_sZr5nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training CNN (Mixed)"
      ],
      "metadata": {
        "id": "lZ4gHpFtsGrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "\n",
        "model_checkpoint = \"timm/resnet50.tv_in1k\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "image_processor = image_processor.data_config\n",
        "image_processor"
      ],
      "metadata": {
        "id": "Wo0bMNjysVqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "      # Geometric Transforms\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05, scale_limit=0.05, rotate_limit=10,\n",
        "        border_mode=cv2.BORDER_REFLECT_101, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Photometric Adjustments\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=0.2, contrast_limit=0.4, p=0.5\n",
        "    ),\n",
        "    A.HueSaturationValue(\n",
        "        hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=30, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Slight blur for optical variance\n",
        "    A.OneOf([\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "        A.MedianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Minor elastic distortion to simulate skin curvature\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=0.5, sigma=20, p=0.5),\n",
        "        A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Slight shadow/illumination simulation\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 3), shadow_dimension=3, shadow_intensity_range=(0.05, 0.1), p=0.2),\n",
        "    A.RandomSunFlare(src_radius=2, flare_roi=(0, 0, 0.2, 0.2), num_flare_circles_range=(1, 2), p=0.2),\n",
        "\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "def preprocess_train(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #train_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        train_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "def preprocess_val(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #val_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        val_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "# split up training into training + validation\n",
        "splits = ds_dermoscopic_train.train_test_split(test_size=0.1)\n",
        "train_ds_dermoscopic = splits['train']\n",
        "val_ds_dermoscopic = splits['test']\n",
        "\n",
        "splits = ds_clinical_train.train_test_split(test_size=0.1)\n",
        "train_ds_clinical = splits['train']\n",
        "val_ds_clinical = splits['test']\n",
        "\n",
        "splits = ds_mixed_train.train_test_split(test_size=0.1)\n",
        "train_ds_mixed = splits['train']\n",
        "val_ds_mixed = splits['test']\n",
        "\n",
        "test_ds_dermoscopic = ds_dermoscopic_test\n",
        "test_ds_clinical = ds_clinical_test\n",
        "test_ds_mixed = ds_mixed_test\n",
        "\n",
        "train_ds_dermoscopic.set_transform(preprocess_train)\n",
        "val_ds_dermoscopic.set_transform(preprocess_val)\n",
        "test_ds_dermoscopic.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_clinical.set_transform(preprocess_train)\n",
        "val_ds_clinical.set_transform(preprocess_val)\n",
        "test_ds_clinical.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_mixed.set_transform(preprocess_train)\n",
        "val_ds_mixed.set_transform(preprocess_val)\n",
        "test_ds_mixed.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "WucxheW3sRaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "Aehl35gisNIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DefaultDataCollator\n",
        "import evaluate\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "metric1 = evaluate.load(\"accuracy\")\n",
        "metric2 = evaluate.load(\"precision\")\n",
        "metric3 = evaluate.load(\"recall\")\n",
        "metric4 = evaluate.load(\"f1\")\n",
        "metric5 = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "\n",
        "    accuracy = metric1.compute(predictions=predictions, references=eval_pred.label_ids)[\"accuracy\"]\n",
        "    precision = metric2.compute(predictions=predictions, references=eval_pred.label_ids)[\"precision\"]\n",
        "    recall = metric3.compute(predictions=predictions, references=eval_pred.label_ids)[\"recall\"]\n",
        "    f1 = metric4.compute(predictions=predictions, references=eval_pred.label_ids)[\"f1\"]\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "output_dir = f\"{model_name}-finetuned\"\n",
        "\n",
        "learning_rate = 1e-4 #1e-5\n",
        "batch_size = 64 #32\n",
        "num_epochs = 50\n",
        "\n",
        "def collate_fn(examples):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for example in examples:\n",
        "        image = np.moveaxis(example[\"pixel_values\"], source=2, destination=0)\n",
        "        images.append(torch.from_numpy(image))\n",
        "        labels.append(example[\"label\"])\n",
        "\n",
        "    pixel_values = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "oi3TUowPsFz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classweight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labeldict), y=labeldict)\n",
        "classweight = torch.tensor(classweight, dtype=torch.float)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    logging_strategy = \"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type = \"cosine_with_restarts\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss_func(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.BCELoss(weight=classweight)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "xeh_XehFsAdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainset: Mixed"
      ],
      "metadata": {
        "id": "OsDPSRMA7RdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_ds_mixed\n",
        "eval_dataset = val_ds_mixed\n",
        "\n",
        "trainer_cnn_mixed = CustomTrainer(\n",
        "    model,\n",
        "    args = training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        "    callbacks=[EarlyStoppingCallback(10)],\n",
        ")"
      ],
      "metadata": {
        "id": "d8ZgbovT64UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_cnn_mixed.train()"
      ],
      "metadata": {
        "id": "7ZudO8pl7HMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "df = pd.DataFrame(trainer_cnn_mixed.state.log_history)\n",
        "df_history = pd.concat([df['loss'][df['loss'] > 0].reset_index(drop=True), df['eval_loss'][df['eval_loss'] > 0].reset_index(drop=True), df['eval_accuracy'][df['eval_accuracy'] > 0].reset_index(drop=True), df['eval_precision'][df['eval_precision'] > 0].reset_index(drop=True), df['eval_recall'][df['eval_recall'] > 0].reset_index(drop=True), df['eval_f1'][df['eval_f1'] > 0].reset_index(drop=True)], axis=1, ignore_index=True)\n",
        "df_history.columns = ['loss', 'eval_loss', 'eval_accuracy', 'eval_precision', 'eval_recall', 'eval_f1']\n",
        "df_history.index += 1\n",
        "\n",
        "plot_training_metrics(df_history)"
      ],
      "metadata": {
        "id": "4XmMaSz4X3cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Dermoscopic"
      ],
      "metadata": {
        "id": "PRONdnQw9WkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_cnn_m_d = trainer_cnn_mixed.predict(test_ds_dermoscopic)\n",
        "print(outputs_cnn_m_d.metrics)\n",
        "plot_confusion_matrix(outputs_cnn_m_d)\n",
        "plot_roc_curve(outputs_cnn_m_d)"
      ],
      "metadata": {
        "id": "1Te2ceGL68Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Clinical"
      ],
      "metadata": {
        "id": "QyFws2GN9XvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_cnn_m_c = trainer_cnn_mixed.predict(test_ds_clinical)\n",
        "print(outputs_cnn_m_c.metrics)\n",
        "plot_confusion_matrix(outputs_cnn_m_c)\n",
        "plot_roc_curve(outputs_cnn_m_c)"
      ],
      "metadata": {
        "id": "LuhfT40l68p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Mixed"
      ],
      "metadata": {
        "id": "ODm_JHAp9ZDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_cnn_m_m = trainer_cnn_mixed.predict(test_ds_mixed)\n",
        "print(outputs_cnn_m_m.metrics)\n",
        "plot_confusion_matrix(outputs_cnn_m_m)\n",
        "plot_roc_curve(outputs_cnn_m_m)"
      ],
      "metadata": {
        "id": "Dgj1khoq6857"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/resnet50.tv_in1k-finetuned')"
      ],
      "metadata": {
        "id": "cRqM_Sa6r7BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training ViT (Dermoscopic)"
      ],
      "metadata": {
        "id": "qrYdNepLgMVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "\n",
        "model_checkpoint = \"timm/vit_base_patch16_224.augreg_in1k\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "image_processor = image_processor.data_config\n",
        "image_processor"
      ],
      "metadata": {
        "id": "mhPbnf9igQ_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "      # Geometric Transforms\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05, scale_limit=0.05, rotate_limit=10,\n",
        "        border_mode=cv2.BORDER_REFLECT_101, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Photometric Adjustments\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=0.2, contrast_limit=0.4, p=0.5\n",
        "    ),\n",
        "    A.HueSaturationValue(\n",
        "        hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=30, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Slight blur for optical variance\n",
        "    A.OneOf([\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "        A.MedianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Minor elastic distortion to simulate skin curvature\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=0.5, sigma=20, p=0.5),\n",
        "        A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Slight shadow/illumination simulation\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 3), shadow_dimension=3, shadow_intensity_range=(0.05, 0.1), p=0.2),\n",
        "    A.RandomSunFlare(src_radius=2, flare_roi=(0, 0, 0.2, 0.2), num_flare_circles_range=(1, 2), p=0.2),\n",
        "\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "def preprocess_train(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #train_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        train_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "def preprocess_val(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #val_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        val_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "# split up training into training + validation\n",
        "splits = ds_dermoscopic_train.train_test_split(test_size=0.1)\n",
        "train_ds_dermoscopic = splits['train']\n",
        "val_ds_dermoscopic = splits['test']\n",
        "\n",
        "splits = ds_clinical_train.train_test_split(test_size=0.1)\n",
        "train_ds_clinical = splits['train']\n",
        "val_ds_clinical = splits['test']\n",
        "\n",
        "splits = ds_mixed_train.train_test_split(test_size=0.1)\n",
        "train_ds_mixed = splits['train']\n",
        "val_ds_mixed = splits['test']\n",
        "\n",
        "test_ds_dermoscopic = ds_dermoscopic_test\n",
        "test_ds_clinical = ds_clinical_test\n",
        "test_ds_mixed = ds_mixed_test\n",
        "\n",
        "train_ds_dermoscopic.set_transform(preprocess_train)\n",
        "val_ds_dermoscopic.set_transform(preprocess_val)\n",
        "test_ds_dermoscopic.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_clinical.set_transform(preprocess_train)\n",
        "val_ds_clinical.set_transform(preprocess_val)\n",
        "test_ds_clinical.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_mixed.set_transform(preprocess_train)\n",
        "val_ds_mixed.set_transform(preprocess_val)\n",
        "test_ds_mixed.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "RuEKpKOaghRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "8VEknrJ0g9F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DefaultDataCollator\n",
        "import evaluate\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "metric1 = evaluate.load(\"accuracy\")\n",
        "metric2 = evaluate.load(\"precision\")\n",
        "metric3 = evaluate.load(\"recall\")\n",
        "metric4 = evaluate.load(\"f1\")\n",
        "metric5 = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "\n",
        "    accuracy = metric1.compute(predictions=predictions, references=eval_pred.label_ids)[\"accuracy\"]\n",
        "    precision = metric2.compute(predictions=predictions, references=eval_pred.label_ids)[\"precision\"]\n",
        "    recall = metric3.compute(predictions=predictions, references=eval_pred.label_ids)[\"recall\"]\n",
        "    f1 = metric4.compute(predictions=predictions, references=eval_pred.label_ids)[\"f1\"]\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "output_dir = f\"{model_name}-finetuned\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "\n",
        "def collate_fn(examples):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for example in examples:\n",
        "        image = np.moveaxis(example[\"pixel_values\"], source=2, destination=0)\n",
        "        images.append(torch.from_numpy(image))\n",
        "        labels.append(example[\"label\"])\n",
        "\n",
        "    pixel_values = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "O9eY1-hdhAP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classweight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labeldict), y=labeldict)\n",
        "classweight = torch.tensor(classweight, dtype=torch.float)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    logging_strategy = \"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type = \"cosine_with_restarts\", #cosine_with_restarts cosine\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss_func(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.BCELoss(weight=classweight)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "KZN2wzdghEjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainset: Dermoscopic"
      ],
      "metadata": {
        "id": "wjgAQLwPhFY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_ds_dermoscopic\n",
        "eval_dataset = val_ds_dermoscopic\n",
        "\n",
        "trainer_vit_dermoscopic = CustomTrainer(\n",
        "    model,\n",
        "    args = training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        "    callbacks=[EarlyStoppingCallback(10)],\n",
        ")\n",
        "\n",
        "trainer_vit_dermoscopic.train()"
      ],
      "metadata": {
        "id": "wiVcc72Rh3KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "df = pd.DataFrame(trainer_vit_dermoscopic.state.log_history)\n",
        "df_history = pd.concat([df['loss'][df['loss'] > 0].reset_index(drop=True), df['eval_loss'][df['eval_loss'] > 0].reset_index(drop=True), df['eval_accuracy'][df['eval_accuracy'] > 0].reset_index(drop=True), df['eval_precision'][df['eval_precision'] > 0].reset_index(drop=True), df['eval_recall'][df['eval_recall'] > 0].reset_index(drop=True), df['eval_f1'][df['eval_f1'] > 0].reset_index(drop=True)], axis=1, ignore_index=True)\n",
        "df_history.columns = ['loss', 'eval_loss', 'eval_accuracy', 'eval_precision', 'eval_recall', 'eval_f1']\n",
        "df_history.index += 1\n",
        "\n",
        "plot_training_metrics(df_history)"
      ],
      "metadata": {
        "id": "sUec9O5niVaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Dermoscopic"
      ],
      "metadata": {
        "id": "yvohxmKFhOO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_vit_d_d = trainer_vit_dermoscopic.predict(test_ds_dermoscopic)\n",
        "print(outputs_vit_d_d.metrics)\n",
        "plot_confusion_matrix(outputs_vit_d_d)\n",
        "plot_roc_curve(outputs_vit_d_d)"
      ],
      "metadata": {
        "id": "c2o5Yq5qibFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Clinical"
      ],
      "metadata": {
        "id": "uMmdl45hhRks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_vit_d_c = trainer_vit_dermoscopic.predict(test_ds_clinical)\n",
        "print(outputs_vit_d_c.metrics)\n",
        "plot_confusion_matrix(outputs_vit_d_c)\n",
        "plot_roc_curve(outputs_vit_d_c)"
      ],
      "metadata": {
        "id": "QwPtBe6fib2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Mixed"
      ],
      "metadata": {
        "id": "gW-HI6fqhTIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_vit_d_m = trainer_vit_dermoscopic.predict(test_ds_mixed)\n",
        "print(outputs_vit_d_m.metrics)\n",
        "plot_confusion_matrix(outputs_vit_d_m)\n",
        "plot_roc_curve(outputs_vit_d_m)"
      ],
      "metadata": {
        "id": "OAw7p1PnichB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/vit_base_patch16_224.augreg_in1k-finetuned')"
      ],
      "metadata": {
        "id": "HAkZB2qncn1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training ViT (Clinical)"
      ],
      "metadata": {
        "id": "GqZTiOPgshTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "\n",
        "model_checkpoint = \"timm/vit_base_patch16_224.augreg_in1k\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "image_processor = image_processor.data_config\n",
        "image_processor"
      ],
      "metadata": {
        "id": "y2xPEhlRskVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "      # Geometric Transforms\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05, scale_limit=0.05, rotate_limit=10,\n",
        "        border_mode=cv2.BORDER_REFLECT_101, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Photometric Adjustments\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=0.2, contrast_limit=0.4, p=0.5\n",
        "    ),\n",
        "    A.HueSaturationValue(\n",
        "        hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=30, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Slight blur for optical variance\n",
        "    A.OneOf([\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "        A.MedianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Minor elastic distortion to simulate skin curvature\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=0.5, sigma=20, p=0.5),\n",
        "        A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Slight shadow/illumination simulation\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 3), shadow_dimension=3, shadow_intensity_range=(0.05, 0.1), p=0.2),\n",
        "    A.RandomSunFlare(src_radius=2, flare_roi=(0, 0, 0.2, 0.2), num_flare_circles_range=(1, 2), p=0.2),\n",
        "\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "def preprocess_train(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #train_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        train_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "def preprocess_val(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #val_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        val_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "# split up training into training + validation\n",
        "splits = ds_dermoscopic_train.train_test_split(test_size=0.1)\n",
        "train_ds_dermoscopic = splits['train']\n",
        "val_ds_dermoscopic = splits['test']\n",
        "\n",
        "splits = ds_clinical_train.train_test_split(test_size=0.1)\n",
        "train_ds_clinical = splits['train']\n",
        "val_ds_clinical = splits['test']\n",
        "\n",
        "splits = ds_mixed_train.train_test_split(test_size=0.1)\n",
        "train_ds_mixed = splits['train']\n",
        "val_ds_mixed = splits['test']\n",
        "\n",
        "test_ds_dermoscopic = ds_dermoscopic_test\n",
        "test_ds_clinical = ds_clinical_test\n",
        "test_ds_mixed = ds_mixed_test\n",
        "\n",
        "train_ds_dermoscopic.set_transform(preprocess_train)\n",
        "val_ds_dermoscopic.set_transform(preprocess_val)\n",
        "test_ds_dermoscopic.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_clinical.set_transform(preprocess_train)\n",
        "val_ds_clinical.set_transform(preprocess_val)\n",
        "test_ds_clinical.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_mixed.set_transform(preprocess_train)\n",
        "val_ds_mixed.set_transform(preprocess_val)\n",
        "test_ds_mixed.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "N9Bi9jI-sm9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "del5MyHUsom4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DefaultDataCollator\n",
        "import evaluate\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "metric1 = evaluate.load(\"accuracy\")\n",
        "metric2 = evaluate.load(\"precision\")\n",
        "metric3 = evaluate.load(\"recall\")\n",
        "metric4 = evaluate.load(\"f1\")\n",
        "metric5 = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "\n",
        "    accuracy = metric1.compute(predictions=predictions, references=eval_pred.label_ids)[\"accuracy\"]\n",
        "    precision = metric2.compute(predictions=predictions, references=eval_pred.label_ids)[\"precision\"]\n",
        "    recall = metric3.compute(predictions=predictions, references=eval_pred.label_ids)[\"recall\"]\n",
        "    f1 = metric4.compute(predictions=predictions, references=eval_pred.label_ids)[\"f1\"]\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "output_dir = f\"{model_name}-finetuned\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "\n",
        "def collate_fn(examples):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for example in examples:\n",
        "        image = np.moveaxis(example[\"pixel_values\"], source=2, destination=0)\n",
        "        images.append(torch.from_numpy(image))\n",
        "        labels.append(example[\"label\"])\n",
        "\n",
        "    pixel_values = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "jQtSWJ_Ystr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classweight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labeldict), y=labeldict)\n",
        "classweight = torch.tensor(classweight, dtype=torch.float)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    logging_strategy = \"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type = \"cosine_with_restarts\", #cosine_with_restarts cosine\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss_func(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.BCELoss(weight=classweight)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "pvGbTU3AsxRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainset: Clinical"
      ],
      "metadata": {
        "id": "FXkVLVzLhJEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_ds_clinical\n",
        "eval_dataset = val_ds_clinical\n",
        "\n",
        "trainer_vit_clinical = CustomTrainer(\n",
        "    model,\n",
        "    args = training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        "    callbacks=[EarlyStoppingCallback(10)],\n",
        ")\n",
        "\n",
        "trainer_vit_clinical.train()"
      ],
      "metadata": {
        "id": "JSKfBrM_iv1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "df = pd.DataFrame(trainer_vit_clinical.state.log_history)\n",
        "df_history = pd.concat([df['loss'][df['loss'] > 0].reset_index(drop=True), df['eval_loss'][df['eval_loss'] > 0].reset_index(drop=True), df['eval_accuracy'][df['eval_accuracy'] > 0].reset_index(drop=True), df['eval_precision'][df['eval_precision'] > 0].reset_index(drop=True), df['eval_recall'][df['eval_recall'] > 0].reset_index(drop=True), df['eval_f1'][df['eval_f1'] > 0].reset_index(drop=True)], axis=1, ignore_index=True)\n",
        "df_history.columns = ['loss', 'eval_loss', 'eval_accuracy', 'eval_precision', 'eval_recall', 'eval_f1']\n",
        "df_history.index += 1\n",
        "\n",
        "plot_training_metrics(df_history)"
      ],
      "metadata": {
        "id": "DmK90zlTix4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Dermoscopic"
      ],
      "metadata": {
        "id": "q5erc1jihVQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_vit_c_d = trainer_vit_clinical.predict(test_ds_dermoscopic)\n",
        "print(outputs_vit_c_d.metrics)\n",
        "plot_confusion_matrix(outputs_vit_c_d)\n",
        "plot_roc_curve(outputs_vit_c_d)"
      ],
      "metadata": {
        "id": "-bwQvqTai8U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Clinical"
      ],
      "metadata": {
        "id": "Y3GTGQLAhWnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_vit_c_c = trainer_vit_clinical.predict(test_ds_clinical)\n",
        "print(outputs_vit_c_c.metrics)\n",
        "plot_confusion_matrix(outputs_vit_c_c)\n",
        "plot_roc_curve(outputs_vit_c_c)"
      ],
      "metadata": {
        "id": "yq2FHXRqi83B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Mixed"
      ],
      "metadata": {
        "id": "nQY6jTGdhYtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_vit_c_m = trainer_vit_clinical.predict(test_ds_mixed)\n",
        "print(outputs_vit_c_m.metrics)\n",
        "plot_confusion_matrix(outputs_vit_c_m)\n",
        "plot_roc_curve(outputs_vit_c_m)"
      ],
      "metadata": {
        "id": "LViHcKl2i9SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/vit_base_patch16_224.augreg_in1k-finetuned')"
      ],
      "metadata": {
        "id": "Mbxvfn90lJwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training ViT (Mixed)"
      ],
      "metadata": {
        "id": "kKCiOH0Rs7se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "\n",
        "model_checkpoint = \"timm/vit_base_patch16_224.augreg_in1k\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "image_processor = image_processor.data_config\n",
        "image_processor"
      ],
      "metadata": {
        "id": "v_HcP2BqtJM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "      # Geometric Transforms\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05, scale_limit=0.05, rotate_limit=10,\n",
        "        border_mode=cv2.BORDER_REFLECT_101, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Photometric Adjustments\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=0.2, contrast_limit=0.4, p=0.5\n",
        "    ),\n",
        "    A.HueSaturationValue(\n",
        "        hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=30, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Slight blur for optical variance\n",
        "    A.OneOf([\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "        A.MedianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Minor elastic distortion to simulate skin curvature\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=0.5, sigma=20, p=0.5),\n",
        "        A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Slight shadow/illumination simulation\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 3), shadow_dimension=3, shadow_intensity_range=(0.05, 0.1), p=0.2),\n",
        "    A.RandomSunFlare(src_radius=2, flare_roi=(0, 0, 0.2, 0.2), num_flare_circles_range=(1, 2), p=0.2),\n",
        "\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "def preprocess_train(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #train_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        train_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "def preprocess_val(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #val_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        val_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "# split up training into training + validation\n",
        "splits = ds_dermoscopic_train.train_test_split(test_size=0.1)\n",
        "train_ds_dermoscopic = splits['train']\n",
        "val_ds_dermoscopic = splits['test']\n",
        "\n",
        "splits = ds_clinical_train.train_test_split(test_size=0.1)\n",
        "train_ds_clinical = splits['train']\n",
        "val_ds_clinical = splits['test']\n",
        "\n",
        "splits = ds_mixed_train.train_test_split(test_size=0.1)\n",
        "train_ds_mixed = splits['train']\n",
        "val_ds_mixed = splits['test']\n",
        "\n",
        "test_ds_dermoscopic = ds_dermoscopic_test\n",
        "test_ds_clinical = ds_clinical_test\n",
        "test_ds_mixed = ds_mixed_test\n",
        "\n",
        "train_ds_dermoscopic.set_transform(preprocess_train)\n",
        "val_ds_dermoscopic.set_transform(preprocess_val)\n",
        "test_ds_dermoscopic.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_clinical.set_transform(preprocess_train)\n",
        "val_ds_clinical.set_transform(preprocess_val)\n",
        "test_ds_clinical.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_mixed.set_transform(preprocess_train)\n",
        "val_ds_mixed.set_transform(preprocess_val)\n",
        "test_ds_mixed.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "paG1oo0ttGfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "HeqpJhyEtFIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DefaultDataCollator\n",
        "import evaluate\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "metric1 = evaluate.load(\"accuracy\")\n",
        "metric2 = evaluate.load(\"precision\")\n",
        "metric3 = evaluate.load(\"recall\")\n",
        "metric4 = evaluate.load(\"f1\")\n",
        "metric5 = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "\n",
        "    accuracy = metric1.compute(predictions=predictions, references=eval_pred.label_ids)[\"accuracy\"]\n",
        "    precision = metric2.compute(predictions=predictions, references=eval_pred.label_ids)[\"precision\"]\n",
        "    recall = metric3.compute(predictions=predictions, references=eval_pred.label_ids)[\"recall\"]\n",
        "    f1 = metric4.compute(predictions=predictions, references=eval_pred.label_ids)[\"f1\"]\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "output_dir = f\"{model_name}-finetuned\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "\n",
        "def collate_fn(examples):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for example in examples:\n",
        "        image = np.moveaxis(example[\"pixel_values\"], source=2, destination=0)\n",
        "        images.append(torch.from_numpy(image))\n",
        "        labels.append(example[\"label\"])\n",
        "\n",
        "    pixel_values = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "kGZgVxR0tDlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classweight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labeldict), y=labeldict)\n",
        "classweight = torch.tensor(classweight, dtype=torch.float)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    logging_strategy = \"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type = \"cosine_with_restarts\", #cosine_with_restarts cosine\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss_func(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.BCELoss(weight=classweight)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "vpqRx7L6s_ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainset: Mixed"
      ],
      "metadata": {
        "id": "H0nVYq4KhMBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_ds_mixed\n",
        "eval_dataset = val_ds_mixed\n",
        "\n",
        "trainer_vit_mixed = CustomTrainer(\n",
        "    model,\n",
        "    args = training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        "    callbacks=[EarlyStoppingCallback(10)],\n",
        ")\n",
        "\n",
        "trainer_vit_mixed.train()"
      ],
      "metadata": {
        "id": "kZXOnh6jjO9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "df = pd.DataFrame(trainer_vit_mixed.state.log_history)\n",
        "df_history = pd.concat([df['loss'][df['loss'] > 0].reset_index(drop=True), df['eval_loss'][df['eval_loss'] > 0].reset_index(drop=True), df['eval_accuracy'][df['eval_accuracy'] > 0].reset_index(drop=True), df['eval_precision'][df['eval_precision'] > 0].reset_index(drop=True), df['eval_recall'][df['eval_recall'] > 0].reset_index(drop=True), df['eval_f1'][df['eval_f1'] > 0].reset_index(drop=True)], axis=1, ignore_index=True)\n",
        "df_history.columns = ['loss', 'eval_loss', 'eval_accuracy', 'eval_precision', 'eval_recall', 'eval_f1']\n",
        "df_history.index += 1\n",
        "\n",
        "plot_training_metrics(df_history)"
      ],
      "metadata": {
        "id": "LyFLAg_ojQRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Dermoscopic"
      ],
      "metadata": {
        "id": "Yzet6AMjhaX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_vit_m_d = trainer_vit_mixed.predict(test_ds_dermoscopic)\n",
        "print(outputs_vit_m_d.metrics)\n",
        "plot_confusion_matrix(outputs_vit_m_d)\n",
        "plot_roc_curve(outputs_vit_m_d)\n",
        "outputs_vit_m_d.metrics"
      ],
      "metadata": {
        "id": "xeoJiaIJjdzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Clinical"
      ],
      "metadata": {
        "id": "x7jdO4umhayO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_vit_m_c = trainer_vit_mixed.predict(test_ds_clinical)\n",
        "print(outputs_vit_m_c.metrics)\n",
        "plot_confusion_matrix(outputs_vit_m_c)\n",
        "plot_roc_curve(outputs_vit_m_c)\n",
        "outputs_vit_m_c.metrics"
      ],
      "metadata": {
        "id": "q5oN_5RTjeMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Mixed"
      ],
      "metadata": {
        "id": "nUBbBNeXhcH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_vit_m_m = trainer_vit_mixed.predict(test_ds_mixed)\n",
        "print(outputs_vit_m_m.metrics)\n",
        "plot_confusion_matrix(outputs_vit_m_m)\n",
        "plot_roc_curve(outputs_vit_m_m)\n",
        "outputs_vit_m_m.metrics"
      ],
      "metadata": {
        "id": "k5s_ZQOyjemb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/vit_base_patch16_224.augreg_in1k-finetuned')"
      ],
      "metadata": {
        "id": "p2EwzdGjlL10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training: Swin (Dermoscopic)"
      ],
      "metadata": {
        "id": "dftN92KMkkM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "\n",
        "model_checkpoint = \"timm/swinv2_base_window8_256.ms_in1k\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "image_processor = image_processor.data_config\n",
        "image_processor"
      ],
      "metadata": {
        "id": "H3dlRUzflOU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "      # Geometric Transforms\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05, scale_limit=0.05, rotate_limit=10,\n",
        "        border_mode=cv2.BORDER_REFLECT_101, p=0.5\n",
        "    ),\n",
        "\n",
        "    # Photometric Adjustments\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=0.2, contrast_limit=0.4, p=0.5\n",
        "    ),\n",
        "    A.HueSaturationValue(\n",
        "        hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=30, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Slight blur for optical variance\n",
        "    A.OneOf([\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "        A.MedianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Minor elastic distortion to simulate skin curvature\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=0.5, sigma=20, p=0.5),\n",
        "        A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Slight shadow/illumination simulation\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 3), shadow_dimension=3, shadow_intensity_range=(0.05, 0.1), p=0.2),\n",
        "    A.RandomSunFlare(src_radius=2, flare_roi=(0, 0, 0.2, 0.2), num_flare_circles_range=(1, 2), p=0.2),\n",
        "\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "def preprocess_train(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #train_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        train_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "def preprocess_val(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #val_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        val_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "# split up training into training + validation\n",
        "splits = ds_dermoscopic_train.train_test_split(test_size=0.1)\n",
        "train_ds_dermoscopic = splits['train']\n",
        "val_ds_dermoscopic = splits['test']\n",
        "\n",
        "splits = ds_clinical_train.train_test_split(test_size=0.1)\n",
        "train_ds_clinical = splits['train']\n",
        "val_ds_clinical = splits['test']\n",
        "\n",
        "splits = ds_mixed_train.train_test_split(test_size=0.1)\n",
        "train_ds_mixed = splits['train']\n",
        "val_ds_mixed = splits['test']\n",
        "\n",
        "test_ds_dermoscopic = ds_dermoscopic_test\n",
        "test_ds_clinical = ds_clinical_test\n",
        "test_ds_mixed = ds_mixed_test\n",
        "\n",
        "train_ds_dermoscopic.set_transform(preprocess_train)\n",
        "val_ds_dermoscopic.set_transform(preprocess_val)\n",
        "test_ds_dermoscopic.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_clinical.set_transform(preprocess_train)\n",
        "val_ds_clinical.set_transform(preprocess_val)\n",
        "test_ds_clinical.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_mixed.set_transform(preprocess_train)\n",
        "val_ds_mixed.set_transform(preprocess_val)\n",
        "test_ds_mixed.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "GJXsxM_4lZME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "gfd1GlBaldP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DefaultDataCollator\n",
        "import evaluate\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "metric1 = evaluate.load(\"accuracy\")\n",
        "metric2 = evaluate.load(\"precision\")\n",
        "metric3 = evaluate.load(\"recall\")\n",
        "metric4 = evaluate.load(\"f1\")\n",
        "metric5 = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "\n",
        "    accuracy = metric1.compute(predictions=predictions, references=eval_pred.label_ids)[\"accuracy\"]\n",
        "    precision = metric2.compute(predictions=predictions, references=eval_pred.label_ids)[\"precision\"]\n",
        "    recall = metric3.compute(predictions=predictions, references=eval_pred.label_ids)[\"recall\"]\n",
        "    f1 = metric4.compute(predictions=predictions, references=eval_pred.label_ids)[\"f1\"]\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "output_dir = f\"{model_name}-finetuned\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "\n",
        "def collate_fn(examples):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for example in examples:\n",
        "        image = np.moveaxis(example[\"pixel_values\"], source=2, destination=0)\n",
        "        images.append(torch.from_numpy(image))\n",
        "        labels.append(example[\"label\"])\n",
        "\n",
        "    pixel_values = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "s8g17LRdlhV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classweight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labeldict), y=labeldict)\n",
        "classweight = torch.tensor(classweight, dtype=torch.float)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    logging_strategy = \"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type = \"cosine_with_restarts\", #cosine_with_restarts cosine\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss_func(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.BCELoss(weight=classweight)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "CrvF3Yd2lk9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainset: Dermoscopic"
      ],
      "metadata": {
        "id": "zAvaHTizkr3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_ds_dermoscopic\n",
        "eval_dataset = val_ds_dermoscopic\n",
        "\n",
        "trainer_swin_dermoscopic = CustomTrainer(\n",
        "    model,\n",
        "    args = training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        "    callbacks=[EarlyStoppingCallback(10)],\n",
        ")\n",
        "\n",
        "trainer_swin_dermoscopic.train()"
      ],
      "metadata": {
        "id": "4zPc0yO9lncU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "df = pd.DataFrame(trainer_swin_dermoscopic.state.log_history)\n",
        "df_history = pd.concat([df['loss'][df['loss'] > 0].reset_index(drop=True), df['eval_loss'][df['eval_loss'] > 0].reset_index(drop=True), df['eval_accuracy'][df['eval_accuracy'] > 0].reset_index(drop=True), df['eval_precision'][df['eval_precision'] > 0].reset_index(drop=True), df['eval_recall'][df['eval_recall'] > 0].reset_index(drop=True), df['eval_f1'][df['eval_f1'] > 0].reset_index(drop=True)], axis=1, ignore_index=True)\n",
        "df_history.columns = ['loss', 'eval_loss', 'eval_accuracy', 'eval_precision', 'eval_recall', 'eval_f1']\n",
        "df_history.index += 1\n",
        "\n",
        "plot_training_metrics(df_history)"
      ],
      "metadata": {
        "id": "g_E4b2VMlqm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Dermoscopic"
      ],
      "metadata": {
        "id": "KpjI66-Tkyoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_swin_d_d = trainer_swin_dermoscopic.predict(test_ds_dermoscopic)\n",
        "print(outputs_swin_d_d.metrics)\n",
        "plot_confusion_matrix(outputs_swin_d_d)\n",
        "plot_roc_curve(outputs_swin_d_d)"
      ],
      "metadata": {
        "id": "BaM2SGi_lsrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Clinical"
      ],
      "metadata": {
        "id": "ml6f_VHvk8XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_swin_d_c = trainer_swin_dermoscopic.predict(test_ds_clinical)\n",
        "print(outputs_swin_d_c.metrics)\n",
        "plot_confusion_matrix(outputs_swin_d_c)\n",
        "plot_roc_curve(outputs_swin_d_c)"
      ],
      "metadata": {
        "id": "VM3Q4sUfltI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Mixed"
      ],
      "metadata": {
        "id": "AEHcV-Puk-Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_swin_d_m = trainer_swin_dermoscopic.predict(test_ds_mixed)\n",
        "print(outputs_swin_d_m.metrics)\n",
        "plot_confusion_matrix(outputs_swin_d_m)\n",
        "plot_roc_curve(outputs_swin_d_m)"
      ],
      "metadata": {
        "id": "Tg_B9Ig8lt3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/swinv2_base_window8_256.ms_in1k-finetuned')"
      ],
      "metadata": {
        "id": "iqDFl7xCtbAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training: Swin (Clinical)"
      ],
      "metadata": {
        "id": "MdwDOTM_ti0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "\n",
        "model_checkpoint = \"timm/swinv2_base_window8_256.ms_in1k\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "image_processor = image_processor.data_config\n",
        "image_processor"
      ],
      "metadata": {
        "id": "AcHtOPgstnjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "      # Geometric Transforms\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05, scale_limit=0.05, rotate_limit=10,\n",
        "        border_mode=cv2.BORDER_REFLECT_101, p=0.5\n",
        "    ),\n",
        "\n",
        "    # Photometric Adjustments\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=0.2, contrast_limit=0.4, p=0.5\n",
        "    ),\n",
        "    A.HueSaturationValue(\n",
        "        hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=30, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Slight blur for optical variance\n",
        "    A.OneOf([\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "        A.MedianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Minor elastic distortion to simulate skin curvature\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=0.5, sigma=20, p=0.5),\n",
        "        A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Slight shadow/illumination simulation\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 3), shadow_dimension=3, shadow_intensity_range=(0.05, 0.1), p=0.2),\n",
        "    A.RandomSunFlare(src_radius=2, flare_roi=(0, 0, 0.2, 0.2), num_flare_circles_range=(1, 2), p=0.2),\n",
        "\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "def preprocess_train(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #train_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        train_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "def preprocess_val(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #val_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        val_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "# split up training into training + validation\n",
        "splits = ds_dermoscopic_train.train_test_split(test_size=0.1)\n",
        "train_ds_dermoscopic = splits['train']\n",
        "val_ds_dermoscopic = splits['test']\n",
        "\n",
        "splits = ds_clinical_train.train_test_split(test_size=0.1)\n",
        "train_ds_clinical = splits['train']\n",
        "val_ds_clinical = splits['test']\n",
        "\n",
        "splits = ds_mixed_train.train_test_split(test_size=0.1)\n",
        "train_ds_mixed = splits['train']\n",
        "val_ds_mixed = splits['test']\n",
        "\n",
        "test_ds_dermoscopic = ds_dermoscopic_test\n",
        "test_ds_clinical = ds_clinical_test\n",
        "test_ds_mixed = ds_mixed_test\n",
        "\n",
        "train_ds_dermoscopic.set_transform(preprocess_train)\n",
        "val_ds_dermoscopic.set_transform(preprocess_val)\n",
        "test_ds_dermoscopic.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_clinical.set_transform(preprocess_train)\n",
        "val_ds_clinical.set_transform(preprocess_val)\n",
        "test_ds_clinical.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_mixed.set_transform(preprocess_train)\n",
        "val_ds_mixed.set_transform(preprocess_val)\n",
        "test_ds_mixed.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "CuYYJnUqtqOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "ezM5T0fHtrwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DefaultDataCollator\n",
        "import evaluate\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "metric1 = evaluate.load(\"accuracy\")\n",
        "metric2 = evaluate.load(\"precision\")\n",
        "metric3 = evaluate.load(\"recall\")\n",
        "metric4 = evaluate.load(\"f1\")\n",
        "metric5 = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "\n",
        "    accuracy = metric1.compute(predictions=predictions, references=eval_pred.label_ids)[\"accuracy\"]\n",
        "    precision = metric2.compute(predictions=predictions, references=eval_pred.label_ids)[\"precision\"]\n",
        "    recall = metric3.compute(predictions=predictions, references=eval_pred.label_ids)[\"recall\"]\n",
        "    f1 = metric4.compute(predictions=predictions, references=eval_pred.label_ids)[\"f1\"]\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "output_dir = f\"{model_name}-finetuned\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "\n",
        "def collate_fn(examples):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for example in examples:\n",
        "        image = np.moveaxis(example[\"pixel_values\"], source=2, destination=0)\n",
        "        images.append(torch.from_numpy(image))\n",
        "        labels.append(example[\"label\"])\n",
        "\n",
        "    pixel_values = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "_wU7mfg7tuJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classweight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labeldict), y=labeldict)\n",
        "classweight = torch.tensor(classweight, dtype=torch.float)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    logging_strategy = \"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type = \"cosine_with_restarts\", #cosine_with_restarts cosine\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss_func(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.BCELoss(weight=classweight)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "rokOkV4StwM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainset: Clinical"
      ],
      "metadata": {
        "id": "6i30LOz2kvXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_ds_clinical\n",
        "eval_dataset = val_ds_clinical\n",
        "\n",
        "trainer_swin_clinical = CustomTrainer(\n",
        "    model,\n",
        "    args = training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        "    callbacks=[EarlyStoppingCallback(10)],\n",
        ")\n",
        "\n",
        "trainer_swin_clinical.train()"
      ],
      "metadata": {
        "id": "y-q1vbgpmauu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "df = pd.DataFrame(trainer_swin_clinical.state.log_history)\n",
        "df_history = pd.concat([df['loss'][df['loss'] > 0].reset_index(drop=True), df['eval_loss'][df['eval_loss'] > 0].reset_index(drop=True), df['eval_accuracy'][df['eval_accuracy'] > 0].reset_index(drop=True), df['eval_precision'][df['eval_precision'] > 0].reset_index(drop=True), df['eval_recall'][df['eval_recall'] > 0].reset_index(drop=True), df['eval_f1'][df['eval_f1'] > 0].reset_index(drop=True)], axis=1, ignore_index=True)\n",
        "df_history.columns = ['loss', 'eval_loss', 'eval_accuracy', 'eval_precision', 'eval_recall', 'eval_f1']\n",
        "df_history.index += 1\n",
        "\n",
        "plot_training_metrics(df_history)"
      ],
      "metadata": {
        "id": "FfK5LBTZmdJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Dermoscopic"
      ],
      "metadata": {
        "id": "_Ht17tzwlAdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_swin_c_d = trainer_swin_clinical.predict(test_ds_dermoscopic)\n",
        "outputs_swin_c_d.metrics\n",
        "plot_confusion_matrix(outputs_swin_c_d)\n",
        "plot_roc_curve(outputs_swin_c_d)"
      ],
      "metadata": {
        "id": "0DQc_q3pmsms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Clinical"
      ],
      "metadata": {
        "id": "CrTsrAgslCHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_swin_c_c = trainer_swin_clinical.predict(test_ds_clinical)\n",
        "print(outputs_swin_c_c.metrics)\n",
        "plot_confusion_matrix(outputs_swin_c_c)\n",
        "plot_roc_curve(outputs_swin_c_c)"
      ],
      "metadata": {
        "id": "5aEM9I6lmvLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Mixed"
      ],
      "metadata": {
        "id": "kiARu_exlDW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_swin_c_m = trainer_swin_clinical.predict(test_ds_mixed)\n",
        "print(outputs_swin_c_m.metrics)\n",
        "plot_confusion_matrix(outputs_swin_c_m)\n",
        "plot_roc_curve(outputs_swin_c_m)"
      ],
      "metadata": {
        "id": "A1BygvWYmvo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/swinv2_base_window8_256.ms_in1k-finetuned')"
      ],
      "metadata": {
        "id": "6A0_u8b8tcy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training: Swin (Mixed)"
      ],
      "metadata": {
        "id": "Gbm_exVrtzeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "\n",
        "model_checkpoint = \"timm/swinv2_base_window8_256.ms_in1k\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "image_processor = image_processor.data_config\n",
        "image_processor"
      ],
      "metadata": {
        "id": "Y9yJc9jmt_sV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "      # Geometric Transforms\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05, scale_limit=0.05, rotate_limit=10,\n",
        "        border_mode=cv2.BORDER_REFLECT_101, p=0.5\n",
        "    ),\n",
        "\n",
        "    # Photometric Adjustments\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=0.2, contrast_limit=0.4, p=0.5\n",
        "    ),\n",
        "    A.HueSaturationValue(\n",
        "        hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=30, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Slight blur for optical variance\n",
        "    A.OneOf([\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "        A.MedianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Minor elastic distortion to simulate skin curvature\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=0.5, sigma=20, p=0.5),\n",
        "        A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Slight shadow/illumination simulation\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 3), shadow_dimension=3, shadow_intensity_range=(0.05, 0.1), p=0.2),\n",
        "    A.RandomSunFlare(src_radius=2, flare_roi=(0, 0, 0.2, 0.2), num_flare_circles_range=(1, 2), p=0.2),\n",
        "\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "def preprocess_train(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #train_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        train_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "def preprocess_val(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #val_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        val_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "# split up training into training + validation\n",
        "splits = ds_dermoscopic_train.train_test_split(test_size=0.1)\n",
        "train_ds_dermoscopic = splits['train']\n",
        "val_ds_dermoscopic = splits['test']\n",
        "\n",
        "splits = ds_clinical_train.train_test_split(test_size=0.1)\n",
        "train_ds_clinical = splits['train']\n",
        "val_ds_clinical = splits['test']\n",
        "\n",
        "splits = ds_mixed_train.train_test_split(test_size=0.1)\n",
        "train_ds_mixed = splits['train']\n",
        "val_ds_mixed = splits['test']\n",
        "\n",
        "test_ds_dermoscopic = ds_dermoscopic_test\n",
        "test_ds_clinical = ds_clinical_test\n",
        "test_ds_mixed = ds_mixed_test\n",
        "\n",
        "train_ds_dermoscopic.set_transform(preprocess_train)\n",
        "val_ds_dermoscopic.set_transform(preprocess_val)\n",
        "test_ds_dermoscopic.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_clinical.set_transform(preprocess_train)\n",
        "val_ds_clinical.set_transform(preprocess_val)\n",
        "test_ds_clinical.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_mixed.set_transform(preprocess_train)\n",
        "val_ds_mixed.set_transform(preprocess_val)\n",
        "test_ds_mixed.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "_MXxcK5Pt8hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "YVYQTvDlt7Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DefaultDataCollator\n",
        "import evaluate\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "metric1 = evaluate.load(\"accuracy\")\n",
        "metric2 = evaluate.load(\"precision\")\n",
        "metric3 = evaluate.load(\"recall\")\n",
        "metric4 = evaluate.load(\"f1\")\n",
        "metric5 = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "\n",
        "    accuracy = metric1.compute(predictions=predictions, references=eval_pred.label_ids)[\"accuracy\"]\n",
        "    precision = metric2.compute(predictions=predictions, references=eval_pred.label_ids)[\"precision\"]\n",
        "    recall = metric3.compute(predictions=predictions, references=eval_pred.label_ids)[\"recall\"]\n",
        "    f1 = metric4.compute(predictions=predictions, references=eval_pred.label_ids)[\"f1\"]\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "output_dir = f\"{model_name}-finetuned\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "\n",
        "def collate_fn(examples):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for example in examples:\n",
        "        image = np.moveaxis(example[\"pixel_values\"], source=2, destination=0)\n",
        "        images.append(torch.from_numpy(image))\n",
        "        labels.append(example[\"label\"])\n",
        "\n",
        "    pixel_values = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "IMxkLn89t5pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classweight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labeldict), y=labeldict)\n",
        "classweight = torch.tensor(classweight, dtype=torch.float)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    logging_strategy = \"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type = \"cosine_with_restarts\", #cosine_with_restarts cosine\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss_func(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.BCELoss(weight=classweight)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "k1HdMTAat2R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainset: Mixed"
      ],
      "metadata": {
        "id": "F53yGjKBkxC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from PIL import Image\n",
        "from datasets import Features, ClassLabel, Image as ImageFeature\n",
        "\n",
        "#Training Sets - Will be later split into train and val set\n",
        "df_dermoscopic = df_train_dermoscopic.copy()\n",
        "df_dermoscopic = df_dermoscopic.rename(columns={'image_path': 'image'})\n",
        "df_dermoscopic['label'] = df_dermoscopic['label'].apply(lambda x: 1 if x == 'BCC' else 0)\n",
        "\n",
        "df_clinical = df_train_clinical.copy()\n",
        "df_clinical = df_clinical.rename(columns={'image_path': 'image'})\n",
        "df_clinical['label'] = df_clinical['label'].apply(lambda x: 1 if x == 'BCC' else 0)\n",
        "\n",
        "df_mixed = df_train_mixed.copy()\n",
        "df_mixed = df_mixed.rename(columns={'image_path': 'image'})\n",
        "df_mixed['label'] = df_mixed['label'].apply(lambda x: 1 if x == 'BCC' else 0)\n",
        "\n",
        "#Test Sets\n",
        "df_dermoscopic_test = df_test_dermoscopic.copy()\n",
        "df_dermoscopic_test = df_dermoscopic_test.rename(columns={'image_path': 'image'})\n",
        "df_dermoscopic_test['label'] = df_dermoscopic_test['label'].apply(lambda x: 1 if x == 'BCC' else 0)\n",
        "\n",
        "df_clinical_test = df_test_clinical.copy()\n",
        "df_clinical_test = df_clinical_test.rename(columns={'image_path': 'image'})\n",
        "df_clinical_test['label'] = df_clinical_test['label'].apply(lambda x: 1 if x == 'BCC' else 0)\n",
        "\n",
        "df_mixed_test = df_test_mixed.copy()\n",
        "df_mixed_test = df_mixed_test.rename(columns={'image_path': 'image'})\n",
        "df_mixed_test['label'] = df_mixed_test['label'].apply(lambda x: 1 if x == 'BCC' else 0)\n",
        "\n",
        "ds_dermoscopic_train = Dataset.from_pandas(df_dermoscopic)\n",
        "ds_clinical_train = Dataset.from_pandas(df_clinical)\n",
        "ds_mixed_train = Dataset.from_pandas(df_mixed)\n",
        "\n",
        "ds_dermoscopic_test = Dataset.from_pandas(df_dermoscopic_test)\n",
        "ds_clinical_test = Dataset.from_pandas(df_clinical_test)\n",
        "ds_mixed_test = Dataset.from_pandas(df_mixed_test)\n",
        "\n",
        "# Cast columns as features\n",
        "ds_dermoscopic_train = ds_dermoscopic_train.cast_column(\"label\", ClassLabel(num_classes=2, names=['SCC', 'BCC']))\n",
        "ds_dermoscopic_train = ds_dermoscopic_train.cast_column(\"image\", ImageFeature())\n",
        "\n",
        "ds_clinical_train = ds_clinical_train.cast_column(\"label\", ClassLabel(num_classes=2, names=['SCC', 'BCC']))\n",
        "ds_clinical_train = ds_clinical_train.cast_column(\"image\", ImageFeature())\n",
        "\n",
        "ds_mixed_train = ds_mixed_train.cast_column(\"label\", ClassLabel(num_classes=2, names=['SCC', 'BCC']))\n",
        "ds_mixed_train = ds_mixed_train.cast_column(\"image\", ImageFeature())\n",
        "\n",
        "ds_dermoscopic_test = ds_dermoscopic_test.cast_column(\"label\", ClassLabel(num_classes=2, names=['SCC', 'BCC']))\n",
        "ds_dermoscopic_test = ds_dermoscopic_test.cast_column(\"image\", ImageFeature())\n",
        "\n",
        "ds_clinical_test = ds_clinical_test.cast_column(\"label\", ClassLabel(num_classes=2, names=['SCC', 'BCC']))\n",
        "ds_clinical_test = ds_clinical_test.cast_column(\"image\", ImageFeature())\n",
        "\n",
        "ds_mixed_test = ds_mixed_test.cast_column(\"label\", ClassLabel(num_classes=2, names=['SCC', 'BCC']))\n",
        "ds_mixed_test = ds_mixed_test.cast_column(\"image\", ImageFeature())"
      ],
      "metadata": {
        "id": "7zMi4jNDeci_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_ds_mixed\n",
        "eval_dataset = val_ds_mixed\n",
        "\n",
        "trainer_swin_mixed = CustomTrainer(\n",
        "    model,\n",
        "    args = training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        "    callbacks=[EarlyStoppingCallback(10)],\n",
        ")\n",
        "\n",
        "trainer_swin_mixed.train()"
      ],
      "metadata": {
        "id": "jqSenVinnWD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "df = pd.DataFrame(trainer_swin_mixed.state.log_history)\n",
        "df_history = pd.concat([df['loss'][df['loss'] > 0].reset_index(drop=True), df['eval_loss'][df['eval_loss'] > 0].reset_index(drop=True), df['eval_accuracy'][df['eval_accuracy'] > 0].reset_index(drop=True), df['eval_precision'][df['eval_precision'] > 0].reset_index(drop=True), df['eval_recall'][df['eval_recall'] > 0].reset_index(drop=True), df['eval_f1'][df['eval_f1'] > 0].reset_index(drop=True)], axis=1, ignore_index=True)\n",
        "df_history.columns = ['loss', 'eval_loss', 'eval_accuracy', 'eval_precision', 'eval_recall', 'eval_f1']\n",
        "df_history.index += 1\n",
        "\n",
        "plot_training_metrics(df_history)"
      ],
      "metadata": {
        "id": "-BRb1OX8ncY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Dermoscopic"
      ],
      "metadata": {
        "id": "vAR-J6iDlBbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_swin_m_d = trainer_swin_mixed.predict(test_ds_dermoscopic)\n",
        "print(outputs_swin_m_d.metrics)\n",
        "plot_confusion_matrix(outputs_swin_m_d)\n",
        "plot_roc_curve(outputs_swin_m_d)\n",
        "outputs_swin_m_d.metrics"
      ],
      "metadata": {
        "id": "gUncT3hDnfJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Clinical"
      ],
      "metadata": {
        "id": "YFzBoOt6lGwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_swin_m_c = trainer_swin_mixed.predict(test_ds_clinical)\n",
        "print(outputs_swin_m_c.metrics)\n",
        "plot_confusion_matrix(outputs_swin_m_c)\n",
        "plot_roc_curve(outputs_swin_m_c)\n",
        "outputs_swin_m_c.metrics"
      ],
      "metadata": {
        "id": "noGViW3BngA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Mixed"
      ],
      "metadata": {
        "id": "4dl3vQxNlIm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_swin_m_m = trainer_swin_mixed.predict(test_ds_mixed)\n",
        "print(outputs_swin_m_m.metrics)\n",
        "plot_confusion_matrix(outputs_swin_m_m)\n",
        "plot_roc_curve(outputs_swin_m_m)\n",
        "outputs_swin_m_m.metrics"
      ],
      "metadata": {
        "id": "uMYugbmqngfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/swinv2_base_window8_256.ms_in1k-finetuned')"
      ],
      "metadata": {
        "id": "Qr9dbIITteIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training: DeiT (Dermoscopic)"
      ],
      "metadata": {
        "id": "tnzkJ73Zn0Vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "\n",
        "model_checkpoint = \"timm/deit3_base_patch16_224.fb_in1k\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "image_processor = image_processor.data_config\n",
        "image_processor"
      ],
      "metadata": {
        "id": "pSFxCIaaoUcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "      # Geometric Transforms\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05, scale_limit=0.05, rotate_limit=10,\n",
        "        border_mode=cv2.BORDER_REFLECT_101, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Photometric Adjustments\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=0.2, contrast_limit=0.4, p=0.5\n",
        "    ),\n",
        "    A.HueSaturationValue(\n",
        "        hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=30, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Slight blur for optical variance\n",
        "    A.OneOf([\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "        A.MedianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Minor elastic distortion to simulate skin curvature\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=0.5, sigma=20, p=0.5),\n",
        "        A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Slight shadow/illumination simulation\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 3), shadow_dimension=3, shadow_intensity_range=(0.05, 0.1), p=0.2),\n",
        "    A.RandomSunFlare(src_radius=2, flare_roi=(0, 0, 0.2, 0.2), num_flare_circles_range=(1, 2), p=0.2),\n",
        "\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "def preprocess_train(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #train_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        train_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "def preprocess_val(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #val_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        val_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "# split up training into training + validation\n",
        "splits = ds_dermoscopic_train.train_test_split(test_size=0.1)\n",
        "train_ds_dermoscopic = splits['train']\n",
        "val_ds_dermoscopic = splits['test']\n",
        "\n",
        "splits = ds_clinical_train.train_test_split(test_size=0.1)\n",
        "train_ds_clinical = splits['train']\n",
        "val_ds_clinical = splits['test']\n",
        "\n",
        "splits = ds_mixed_train.train_test_split(test_size=0.1)\n",
        "train_ds_mixed = splits['train']\n",
        "val_ds_mixed = splits['test']\n",
        "\n",
        "test_ds_dermoscopic = ds_dermoscopic_test\n",
        "test_ds_clinical = ds_clinical_test\n",
        "test_ds_mixed = ds_mixed_test\n",
        "\n",
        "train_ds_dermoscopic.set_transform(preprocess_train)\n",
        "val_ds_dermoscopic.set_transform(preprocess_val)\n",
        "test_ds_dermoscopic.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_clinical.set_transform(preprocess_train)\n",
        "val_ds_clinical.set_transform(preprocess_val)\n",
        "test_ds_clinical.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_mixed.set_transform(preprocess_train)\n",
        "val_ds_mixed.set_transform(preprocess_val)\n",
        "test_ds_mixed.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "9KYdfLJDoZoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "p5kQRbq_ockx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DefaultDataCollator\n",
        "import evaluate\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "metric1 = evaluate.load(\"accuracy\")\n",
        "metric2 = evaluate.load(\"precision\")\n",
        "metric3 = evaluate.load(\"recall\")\n",
        "metric4 = evaluate.load(\"f1\")\n",
        "metric5 = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "\n",
        "    accuracy = metric1.compute(predictions=predictions, references=eval_pred.label_ids)[\"accuracy\"]\n",
        "    precision = metric2.compute(predictions=predictions, references=eval_pred.label_ids)[\"precision\"]\n",
        "    recall = metric3.compute(predictions=predictions, references=eval_pred.label_ids)[\"recall\"]\n",
        "    f1 = metric4.compute(predictions=predictions, references=eval_pred.label_ids)[\"f1\"]\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "output_dir = f\"{model_name}-finetuned\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "\n",
        "def collate_fn(examples):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for example in examples:\n",
        "        image = np.moveaxis(example[\"pixel_values\"], source=2, destination=0)\n",
        "        images.append(torch.from_numpy(image))\n",
        "        labels.append(example[\"label\"])\n",
        "\n",
        "    pixel_values = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "XhopS9G9ofUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classweight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labeldict), y=labeldict)\n",
        "classweight = torch.tensor(classweight, dtype=torch.float)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    logging_strategy = \"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type = \"cosine_with_restarts\", #cosine_with_restarts cosine\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss_func(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.BCELoss(weight=classweight)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "1No7QaR5ojxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainset: Dermoscopic"
      ],
      "metadata": {
        "id": "Vt8zYi2qn6vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_ds_dermoscopic\n",
        "eval_dataset = val_ds_dermoscopic\n",
        "\n",
        "trainer_deit_dermoscopic = CustomTrainer(\n",
        "    model,\n",
        "    args = training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        "    callbacks=[EarlyStoppingCallback(10)],\n",
        ")\n",
        "\n",
        "trainer_deit_dermoscopic.train()"
      ],
      "metadata": {
        "id": "vwPD8Zonom1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "df = pd.DataFrame(trainer_deit_dermoscopic.state.log_history)\n",
        "df_history = pd.concat([df['loss'][df['loss'] > 0].reset_index(drop=True), df['eval_loss'][df['eval_loss'] > 0].reset_index(drop=True), df['eval_accuracy'][df['eval_accuracy'] > 0].reset_index(drop=True), df['eval_precision'][df['eval_precision'] > 0].reset_index(drop=True), df['eval_recall'][df['eval_recall'] > 0].reset_index(drop=True), df['eval_f1'][df['eval_f1'] > 0].reset_index(drop=True)], axis=1, ignore_index=True)\n",
        "df_history.columns = ['loss', 'eval_loss', 'eval_accuracy', 'eval_precision', 'eval_recall', 'eval_f1']\n",
        "df_history.index += 1\n",
        "\n",
        "plot_training_metrics(df_history)"
      ],
      "metadata": {
        "id": "G0hWhmQnoqY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Dermoscopic"
      ],
      "metadata": {
        "id": "ary2ZsByoAfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_deit_d_d = trainer_deit_dermoscopic.predict(test_ds_dermoscopic)\n",
        "print(outputs_deit_d_d.metrics)\n",
        "plot_confusion_matrix(outputs_deit_d_d)\n",
        "plot_roc_curve(outputs_deit_d_d)"
      ],
      "metadata": {
        "id": "VsssBBITo1Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Clinical"
      ],
      "metadata": {
        "id": "bJMRl82AoD7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_deit_d_c = trainer_deit_dermoscopic.predict(test_ds_clinical)\n",
        "print(outputs_deit_d_c.metrics)\n",
        "plot_confusion_matrix(outputs_deit_d_c)\n",
        "plot_roc_curve(outputs_deit_d_c)"
      ],
      "metadata": {
        "id": "4FZITuXdo7hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Mixed"
      ],
      "metadata": {
        "id": "oS9-VIW3oJ-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_deit_d_m = trainer_deit_dermoscopic.predict(test_ds_mixed)\n",
        "print(outputs_deit_d_m.metrics)\n",
        "plot_confusion_matrix(outputs_deit_d_m)\n",
        "plot_roc_curve(outputs_deit_d_m)"
      ],
      "metadata": {
        "id": "iBc-_ag9pBN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/deit3_base_patch16_224.fb_in1k-finetuned')"
      ],
      "metadata": {
        "id": "uNOt_wjIuH7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training: DeiT (Clinical)"
      ],
      "metadata": {
        "id": "y9GpB5PiuRsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "\n",
        "model_checkpoint = \"timm/deit3_base_patch16_224.fb_in1k\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "image_processor = image_processor.data_config\n",
        "image_processor"
      ],
      "metadata": {
        "id": "XIt0vSzxugYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "      # Geometric Transforms\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05, scale_limit=0.05, rotate_limit=10,\n",
        "        border_mode=cv2.BORDER_REFLECT_101, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Photometric Adjustments\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=0.2, contrast_limit=0.4, p=0.5\n",
        "    ),\n",
        "    A.HueSaturationValue(\n",
        "        hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=30, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Slight blur for optical variance\n",
        "    A.OneOf([\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "        A.MedianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Minor elastic distortion to simulate skin curvature\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=0.5, sigma=20, p=0.5),\n",
        "        A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Slight shadow/illumination simulation\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 3), shadow_dimension=3, shadow_intensity_range=(0.05, 0.1), p=0.2),\n",
        "    A.RandomSunFlare(src_radius=2, flare_roi=(0, 0, 0.2, 0.2), num_flare_circles_range=(1, 2), p=0.2),\n",
        "\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "def preprocess_train(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #train_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        train_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "def preprocess_val(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #val_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        val_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "# split up training into training + validation\n",
        "splits = ds_dermoscopic_train.train_test_split(test_size=0.1)\n",
        "train_ds_dermoscopic = splits['train']\n",
        "val_ds_dermoscopic = splits['test']\n",
        "\n",
        "splits = ds_clinical_train.train_test_split(test_size=0.1)\n",
        "train_ds_clinical = splits['train']\n",
        "val_ds_clinical = splits['test']\n",
        "\n",
        "splits = ds_mixed_train.train_test_split(test_size=0.1)\n",
        "train_ds_mixed = splits['train']\n",
        "val_ds_mixed = splits['test']\n",
        "\n",
        "test_ds_dermoscopic = ds_dermoscopic_test\n",
        "test_ds_clinical = ds_clinical_test\n",
        "test_ds_mixed = ds_mixed_test\n",
        "\n",
        "train_ds_dermoscopic.set_transform(preprocess_train)\n",
        "val_ds_dermoscopic.set_transform(preprocess_val)\n",
        "test_ds_dermoscopic.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_clinical.set_transform(preprocess_train)\n",
        "val_ds_clinical.set_transform(preprocess_val)\n",
        "test_ds_clinical.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_mixed.set_transform(preprocess_train)\n",
        "val_ds_mixed.set_transform(preprocess_val)\n",
        "test_ds_mixed.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "W14bS4__ud6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "W17lRlwWucxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DefaultDataCollator\n",
        "import evaluate\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "metric1 = evaluate.load(\"accuracy\")\n",
        "metric2 = evaluate.load(\"precision\")\n",
        "metric3 = evaluate.load(\"recall\")\n",
        "metric4 = evaluate.load(\"f1\")\n",
        "metric5 = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "\n",
        "    accuracy = metric1.compute(predictions=predictions, references=eval_pred.label_ids)[\"accuracy\"]\n",
        "    precision = metric2.compute(predictions=predictions, references=eval_pred.label_ids)[\"precision\"]\n",
        "    recall = metric3.compute(predictions=predictions, references=eval_pred.label_ids)[\"recall\"]\n",
        "    f1 = metric4.compute(predictions=predictions, references=eval_pred.label_ids)[\"f1\"]\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "output_dir = f\"{model_name}-finetuned\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "\n",
        "def collate_fn(examples):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for example in examples:\n",
        "        image = np.moveaxis(example[\"pixel_values\"], source=2, destination=0)\n",
        "        images.append(torch.from_numpy(image))\n",
        "        labels.append(example[\"label\"])\n",
        "\n",
        "    pixel_values = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "YXBNsKO8ubca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classweight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labeldict), y=labeldict)\n",
        "classweight = torch.tensor(classweight, dtype=torch.float)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    logging_strategy = \"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type = \"cosine_with_restarts\", #cosine_with_restarts cosine\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss_func(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.BCELoss(weight=classweight)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "ztw4rtlwuaA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainset: Clinical"
      ],
      "metadata": {
        "id": "tCoGvOeln9o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_ds_clinical\n",
        "eval_dataset = val_ds_clinical\n",
        "\n",
        "trainer_deit_clinical = CustomTrainer(\n",
        "    model,\n",
        "    args = training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        "    callbacks=[EarlyStoppingCallback(10)],\n",
        ")\n",
        "\n",
        "trainer_deit_clinical.train()"
      ],
      "metadata": {
        "id": "yNd6J2JMpGYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "df = pd.DataFrame(trainer_deit_clinical.state.log_history)\n",
        "df_history = pd.concat([df['loss'][df['loss'] > 0].reset_index(drop=True), df['eval_loss'][df['eval_loss'] > 0].reset_index(drop=True), df['eval_accuracy'][df['eval_accuracy'] > 0].reset_index(drop=True), df['eval_precision'][df['eval_precision'] > 0].reset_index(drop=True), df['eval_recall'][df['eval_recall'] > 0].reset_index(drop=True), df['eval_f1'][df['eval_f1'] > 0].reset_index(drop=True)], axis=1, ignore_index=True)\n",
        "df_history.columns = ['loss', 'eval_loss', 'eval_accuracy', 'eval_precision', 'eval_recall', 'eval_f1']\n",
        "df_history.index += 1\n",
        "\n",
        "plot_training_metrics(df_history)"
      ],
      "metadata": {
        "id": "9sJahX4zpHov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Dermoscopic"
      ],
      "metadata": {
        "id": "1PIuUjxUoFCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_deit_c_d = trainer_deit_clinical.predict(test_ds_dermoscopic)\n",
        "print(outputs_deit_c_d.metrics)\n",
        "plot_confusion_matrix(outputs_deit_c_d)\n",
        "plot_roc_curve(outputs_deit_c_d)\n",
        "outputs_deit_c_d.metrics"
      ],
      "metadata": {
        "id": "8CgovGcMpPXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Clinical"
      ],
      "metadata": {
        "id": "pnJbWq1coIY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_deit_c_c = trainer_deit_clinical.predict(test_ds_clinical)\n",
        "print(outputs_deit_c_c.metrics)\n",
        "plot_confusion_matrix(outputs_deit_c_c)\n",
        "plot_roc_curve(outputs_deit_c_c)\n",
        "outputs_deit_c_c.metrics"
      ],
      "metadata": {
        "id": "XcK-VqnepUYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Mixed"
      ],
      "metadata": {
        "id": "5iZcbl22oMwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_deit_c_m = trainer_deit_clinical.predict(test_ds_mixed)\n",
        "print(outputs_deit_c_m.metrics)\n",
        "plot_confusion_matrix(outputs_deit_c_m)\n",
        "plot_roc_curve(outputs_deit_c_m)\n",
        "outputs_deit_c_m.metrics"
      ],
      "metadata": {
        "id": "vP8PG04spU2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/deit3_base_patch16_224.fb_in1k-finetuned')"
      ],
      "metadata": {
        "id": "Gjl66wOvuJ03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training: DeiT (Mixed)"
      ],
      "metadata": {
        "id": "AhJ455dxum7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "\n",
        "model_checkpoint = \"timm/deit3_base_patch16_224.fb_in1k\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "image_processor = image_processor.data_config\n",
        "image_processor"
      ],
      "metadata": {
        "id": "bMKEr_U-u0GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "      # Geometric Transforms\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05, scale_limit=0.05, rotate_limit=10,\n",
        "        border_mode=cv2.BORDER_REFLECT_101, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Photometric Adjustments\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=0.2, contrast_limit=0.4, p=0.5\n",
        "    ),\n",
        "    A.HueSaturationValue(\n",
        "        hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=30, p=0.4\n",
        "    ),\n",
        "\n",
        "    # Slight blur for optical variance\n",
        "    A.OneOf([\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "        A.MedianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Minor elastic distortion to simulate skin curvature\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=0.5, sigma=20, p=0.5),\n",
        "        A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
        "    ], p=0.3),\n",
        "\n",
        "    # Slight shadow/illumination simulation\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_limit=(1, 3), shadow_dimension=3, shadow_intensity_range=(0.05, 0.1), p=0.2),\n",
        "    A.RandomSunFlare(src_radius=2, flare_roi=(0, 0, 0.2, 0.2), num_flare_circles_range=(1, 2), p=0.2),\n",
        "\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(height=image_processor['input_size'][1], width=image_processor['input_size'][2]),\n",
        "    A.Normalize(\n",
        "        mean=(image_processor['mean'][0], image_processor['mean'][1], image_processor['mean'][2]),\n",
        "        std=(image_processor['std'][0], image_processor['std'][1], image_processor['std'][2]),\n",
        "        p=1.0\n",
        "    ),\n",
        "])\n",
        "\n",
        "def preprocess_train(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #train_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        train_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "def preprocess_val(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        #val_transforms(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
        "        val_transforms(image=np.array(img.convert(\"RGB\")))[\"image\"] for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    return examples\n",
        "\n",
        "# split up training into training + validation\n",
        "splits = ds_dermoscopic_train.train_test_split(test_size=0.1)\n",
        "train_ds_dermoscopic = splits['train']\n",
        "val_ds_dermoscopic = splits['test']\n",
        "\n",
        "splits = ds_clinical_train.train_test_split(test_size=0.1)\n",
        "train_ds_clinical = splits['train']\n",
        "val_ds_clinical = splits['test']\n",
        "\n",
        "splits = ds_mixed_train.train_test_split(test_size=0.1)\n",
        "train_ds_mixed = splits['train']\n",
        "val_ds_mixed = splits['test']\n",
        "\n",
        "test_ds_dermoscopic = ds_dermoscopic_test\n",
        "test_ds_clinical = ds_clinical_test\n",
        "test_ds_mixed = ds_mixed_test\n",
        "\n",
        "train_ds_dermoscopic.set_transform(preprocess_train)\n",
        "val_ds_dermoscopic.set_transform(preprocess_val)\n",
        "test_ds_dermoscopic.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_clinical.set_transform(preprocess_train)\n",
        "val_ds_clinical.set_transform(preprocess_val)\n",
        "test_ds_clinical.set_transform(preprocess_val)\n",
        "\n",
        "train_ds_mixed.set_transform(preprocess_train)\n",
        "val_ds_mixed.set_transform(preprocess_val)\n",
        "test_ds_mixed.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "RWKwKXb6uwO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "CCjXQvGeuu0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DefaultDataCollator\n",
        "import evaluate\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "metric1 = evaluate.load(\"accuracy\")\n",
        "metric2 = evaluate.load(\"precision\")\n",
        "metric3 = evaluate.load(\"recall\")\n",
        "metric4 = evaluate.load(\"f1\")\n",
        "metric5 = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "\n",
        "    accuracy = metric1.compute(predictions=predictions, references=eval_pred.label_ids)[\"accuracy\"]\n",
        "    precision = metric2.compute(predictions=predictions, references=eval_pred.label_ids)[\"precision\"]\n",
        "    recall = metric3.compute(predictions=predictions, references=eval_pred.label_ids)[\"recall\"]\n",
        "    f1 = metric4.compute(predictions=predictions, references=eval_pred.label_ids)[\"f1\"]\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "output_dir = f\"{model_name}-finetuned\"\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "\n",
        "def collate_fn(examples):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for example in examples:\n",
        "        image = np.moveaxis(example[\"pixel_values\"], source=2, destination=0)\n",
        "        images.append(torch.from_numpy(image))\n",
        "        labels.append(example[\"label\"])\n",
        "\n",
        "    pixel_values = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "kPgit650utT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classweight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labeldict), y=labeldict)\n",
        "classweight = torch.tensor(classweight, dtype=torch.float)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    remove_unused_columns=False,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    logging_strategy = \"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    lr_scheduler_type = \"cosine_with_restarts\", #cosine_with_restarts cosine\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss_func(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.BCELoss(weight=classweight)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "uMadhvdGurvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainset: Mixed"
      ],
      "metadata": {
        "id": "Pbw8f9w5n-7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_ds_mixed\n",
        "eval_dataset = val_ds_mixed\n",
        "\n",
        "trainer_deit_mixed = CustomTrainer(\n",
        "    model,\n",
        "    args = training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        "    callbacks=[EarlyStoppingCallback(10)],\n",
        ")\n",
        "\n",
        "trainer_deit_mixed.train()"
      ],
      "metadata": {
        "id": "u0BtNANgpewB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "df = pd.DataFrame(trainer_deit_mixed.state.log_history)\n",
        "df_history = pd.concat([df['loss'][df['loss'] > 0].reset_index(drop=True), df['eval_loss'][df['eval_loss'] > 0].reset_index(drop=True), df['eval_accuracy'][df['eval_accuracy'] > 0].reset_index(drop=True), df['eval_precision'][df['eval_precision'] > 0].reset_index(drop=True), df['eval_recall'][df['eval_recall'] > 0].reset_index(drop=True), df['eval_f1'][df['eval_f1'] > 0].reset_index(drop=True)], axis=1, ignore_index=True)\n",
        "df_history.columns = ['loss', 'eval_loss', 'eval_accuracy', 'eval_precision', 'eval_recall', 'eval_f1']\n",
        "df_history.index += 1\n",
        "\n",
        "plot_training_metrics(df_history)"
      ],
      "metadata": {
        "id": "xyGoygU0pgxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Dermoscopic"
      ],
      "metadata": {
        "id": "C3tfIRygoFdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_deit_m_d = trainer_deit_mixed.predict(test_ds_dermoscopic)\n",
        "print(outputs_deit_m_d.metrics)\n",
        "plot_confusion_matrix(outputs_deit_m_d)\n",
        "plot_roc_curve(outputs_deit_m_d)\n",
        "outputs_deit_m_d.metrics"
      ],
      "metadata": {
        "id": "J7CZCPdwpoWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Clinical"
      ],
      "metadata": {
        "id": "UGQTVaz7oJIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_deit_m_c = trainer_deit_mixed.predict(test_ds_clinical)\n",
        "print(outputs_deit_m_c.metrics)\n",
        "plot_confusion_matrix(outputs_deit_m_c)\n",
        "plot_roc_curve(outputs_deit_m_c)\n",
        "outputs_deit_m_c.metrics"
      ],
      "metadata": {
        "id": "in7RccGZpuKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testset: Mixed"
      ],
      "metadata": {
        "id": "p3Ol968foQlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_deit_m_m = trainer_deit_mixed.predict(test_ds_mixed)\n",
        "print(outputs_deit_m_m.metrics)\n",
        "plot_confusion_matrix(outputs_deit_m_m)\n",
        "plot_roc_curve(outputs_deit_m_m)\n",
        "outputs_deit_m_m.metrics"
      ],
      "metadata": {
        "id": "X1JY8-ETpuhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/deit3_base_patch16_224.fb_in1k-finetuned')"
      ],
      "metadata": {
        "id": "DiR7YOQLuLL8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
